Positive 43427 pIm having trouble understanding which part of the Xpath to select when trying to scrape certain elements of a website. In this case, I am trying to scrape all the websites that are linked in this article for example, this section of the xpath p  precodedatatrackBody Text Link External hrefhttpwww.uspreventiveservicestaskforce.orgPageDocumentRecommendationStatementFinalbrcarelatedcancerriskassessmentgeneticcounselingandgenetictestinggt codepre  pMy spider works but it doesnt scrape anythingp  pMy code is belowp  precodeimport scrapy from scrapy.selector import Selector  from nymag.items import nymagItem  class nymagSpiderscrapy.Spider     name  nymag     alloweddomains  [httpwwww.nymag.com]     starturls  [httpnymag.comthecut201509shouldweallgetthebreastcancergenetest.html]      def parseself, response         Im pretty sure the below line is the issue         links  Selectorresponse.xpath[idprimary]mainarticledivspan         for link in links             item  nymagItem             This might also be wrong  am trying to extract the href section             item[link]  question.xpathahref.extract             yield item codepre
Positive 43427 pSample htmlp  precodeltdiv idfoobar foohelloworldbarbazgtblablablaltdivgt codepre  pIm using codeLinkExtractorcode to get the attribute codefoocode, namely the string codehelloworldbarbazcode. I wonder if its possible to turn this string into multiple urls for the spider to follow, like codehello.comcode, codeworld.comcode, etc.p  pAny help is appreciated.p  pPS the following might or might not be usefulp  ol licodeprocessvaluecode argument of a hrefhttpdoc.scrapy.orgen1.0topicslinkextractors.htmlmodulescrapy.linkextractors.lxmlhtml relnofollowcodeLxmlLinkExtractorcodeali licodeprocesslinkscode argument of a hrefhttpdoc.scrapy.orgen1.0topicsspiders.htmlcrawlingrules relnofollowcodeRulescodeali ol
Positive 43427 pI would like to build a small web app where the user can enter his email and his password so that it shows his Linkedin contact list. Do you have any idea how to do that p  p I know we could do that a few months ago with the Linkedin API but I think its not possible now be can only have basic profile info.p  p Ive been trying using scrapy but at the user login, Linkedin uses a security I cant go through they generate and send a code by email for a new connection.p
Positive 43427 pIm using Scrapy to crawl a webpage, and when i get the results in xml they are not nested as it should be, or at least not as i was expecting them to be.p  precodedef parseself, response     hxs  Selectorresponse     titles  hxs.xpathdiv[classteaserarticles]     items  []     for titles in titles         item  CraigslistSampleItem         item [title]  titles.select..div[classheadline]h1atext.extract         item [link]  titles.select.div[classheadline]h1ahref.extract         item [photo]  titles.select.div[classarticleimg]imgsrc.extract         item [desc]  titles.select.div[classitembg]ptext.extract         items.appenditem         return items codepre  pI get the values that i need t get but i get them in the formatp  precodeltitemgt         ltphotogt             ltvaluegtimagesresizedimagesstories20150910suvenirnica1160160100.jpgltvaluegt             ltvaluegtimagesresizedimagesstories20150909azilantiiii160100.jpgltvaluegt             ltvaluegtimagesresizedimagesstories20150909dzeriiiiii160100.jpgltvaluegt         ltphotogt codepre  pand they should bi likep  precode  ltphotogt         ltvaluegtimagesresizedimagesstories20150910suvenirnica1160160100.jpgltvaluegt   ltphotogt   ltphotogt         ltvaluegtimagesresizedimagesstories20150909azilantiiii160100.jpgltvaluegt   ltphotogt   ltphotogt         ltvaluegtimagesresizedimagesstories20150909dzeriiiiii160100.jpgltvaluegt ltphotogt ltphotogt codepre
Positive 43427 pIm trying to scrape search results from this pagep  pa hrefhttpeurlex.europa.eusearch.htmlqid1437402891621ampDBTYPEOFACTadvGeneralampCASELAWSUMMARYfalseampDTSDOMEULAWamptypeOfActStatusADVGENERALamptypeadvancedamplangenampSUBDOMINITEUCASELAWampDTSSUBDOMEUCASELAW relnofollowhttpeurlex.europa.eusearch.htmlqid1437402891621ampDBTYPEOFACTadvGeneralampCASELAWSUMMARYfalseampDTSDOMEULAWamptypeOfActStatusADVGENERALamptypeadvancedamplangframpSUBDOMINITEUCASELAWampDTSSUBDOMEUCASELAWap  pThe language according to the url is french, and that is what I see in the scrapy shell, following crawled 200 p  pIf I try response.url I also get a url with langfr.p  pViewing the page in a browser shows me french results.p  pHowever, the body of the response is English.p  pIve tried disabling cookies in my scrapy settings.py file. Ive also set the DEFAULTREQUEST HEADERS to AcceptLanguage fr.p  pAny ideasp
Positive 43427 pI have a question that I do not know the answer and it might be interesting. I am crawling for a link like that p  precode    lta hrefhttpwww.sandoz.comcareerscareeropportunitiesjoboffersindex.shtmlgtProsta delovna mesta  v Sandozultagt codepre  pand now that I have found it I would also like to have the text of the  tag Prosta delovna mesta v Sandozup  pHow do I get the text It seems easy with plain String and this would the solutionp  precode    response.xpatha[hrefhttpwww.sandoz.comcareerscareeropportunitiesjoboffersindex.shtml]text.extract codepre  pbut I am in a loop and I only have reference to this url. I tried several options likep  precode    response.xpatha[hrefurlorig]text.extract     response.xpatha[hrefurlorig]text.extract      word  career     response.xpatha[containshref, s]text.extract  word codepre  pBut none of them works. I am sort of looking how to put a reference instead of a string into href or contains function. Here is my code. Do you think there is a way to do it p  pThank you Markop  precodedef parseself, response      response.selector.removenamespaces         We take all urls, they are marked by href. These are either webpages on our website either new websites.     urls  response.xpathhref.extract       Base url.     baseurl  getbaseurlresponse        Loop through all urls on the webpage.     for url in urls          If url represents a picture, a document, a compression ... we ignore it. We might have to change that because some companies provide job vacancies information in PDF.         if url.endswith             images             .jpg, .jpeg, .png, .gif, .eps, .ico,              .JPG, .JPEG, .PNG, .GIF, .EPS, .ICO,               documents             .xls, .ppt, .doc, .xlsx, .pptx, .docx, .txt, .csv, .pdf,              .XLS, .PPT, .DOC, .XLSX, .PPTX, .DOCX, .TXT, .CSV, .PDF,               music and video             .mp3, .mp4, .mpg, .ai, .avi,             .MP3, .MP4, .MPG, .AI, .AVI,              compressions and other             .zip, .rar, .css, .flv,             .ZIP, .RAR, .CSS, .FLV,                        continue           If url includes characters like , , amp,  ... it is LIKELY NOT to be the one we are looking for and we ignore it.          However in this case we exclude good urls like httpwww.mdm.sicompanyemployment         if anyx in url for x in [, , amp, ]             continue          Ignore ftp.         if url.startswithftp             continue          If url doesnt start with http, it is relative url, and we add base url to get absolute url.           It is true, that we may get some strange urls, but it is fine for now.         if not url.startswithhttp              urlorig  url             url  urljoinbaseurl,url           We dont want to go to other websites. We want to stay on our website, so we keep only urls with domain netloc of the company we are investigating.                  if urlparseurl.netloc  urlparsebaseurl.netloc               The main part. We look for webpages, whose urls include one of the employment words as strings.                Instruction.                Users in other languages, please insert employment words in your own language, like jobs, vacancies, career, employment ...              if anyx in url for x in [                  careers,                 Careers,                  jobs,                 Jobs,                  employment,                                                    Employment,                   joinus,                 JoinUs,                 Joinus                  vacancies,                 Vacancies,                  workforus,                  workingwithus,                  joinus,               ]                 We found url that includes one of the magic words. We check, if we have found it before. If it is new, we add it to the list jobsurls.                 if url not in self.jobsurls                     self.jobsurls.appendurl                     item  JobItem                     item[link]  url                     item[term]  response.xpatha[hrefurlorig]text.extract                      item[term]  response.xpatha[containshref, career]text.extract                       We return the item.                     yield item              We dont put else sentence because we want to explore the employment webpage to find possible new employment webpages.             We keep looking for employment webpages, until we reach the DEPTH, that we have set in settings.py.              yield Requesturl, callback  self.parse codepre
Positive 43427 pI am actually very new to Scrapy and Im not sure why am I not getting the information which I want. I am using Scrapy on the website www.kayak.com and i want to extract the check in and check out time from all the hotels in New York. I have successfully scraped out data from the same page which the check in and check out time is in but couldnt scrape out data for both these fields. p  pThe code I have is shown below p  precodeimport scrapy from scrapy.spiders import CrawlSpider, Rule from scrapy.linkextractors import LinkExtractor from hotelcrawl.items import HotelCrawlItem from bs4 import BeautifulSoup import time import urlparse  class MySpiderCrawlSpider name  kayaksite alloweddomains  [www.kayak.com] starturls  [httpwww.kayak.comNewYorkHotels.15830.hotel.ksp]  rules       RuleLinkExtractor     restrictxpathsa[classactionlink pagenumber [containstext,Next], , callbackparseitem, followTrue,  def parsestarturlself, response     print test     self.logger.infoHi, this is an item page s, response.url     item  HotelCrawlItem      name  response.xpatha[classhotelname hotelresultsname]text.extract     price  [BeautifulSoupi.gettext for i in response.xpathdiv[classpricerange].extract] review  response.xpatha[classreviewsoverview]strongtext.extract      url  response.xpatha[classhotelname hotelresultsname]href.extract      alldata  zipname, price, review, url      for i in alldata         item[name]  i[0]         item[price]  i[1]         item[review]  i[2]         request  scrapy.Requesturlparse.urljoinresponse.url, i[3], callbackself.parseitem2          request.meta[item]  item         yield request   def parseitemself, response     self.logger.infoHi, this is an item page s, response.url     item  HotelCrawlItem     name  response.xpatha[classhotelname hotelresultsname]text.extract     price  [BeautifulSoupi.gettext for i in response.xpathdiv[classpricerange].extract]     review  response.xpatha[classreviewsoverview]strongtext.extract     url  response.xpatha[classhotelname hotelresultsname]href.extract      alldata  zipname, price, review, url      for i in alldata         item[name]  i[0]         item[price]  i[1]         item[review]  i[2]         request  scrapy.Requesturlparse.urljoinresponse.url, i[3], callbackself.parseitem2         request.meta[item]  item         yield request  def parseitem2self, response     print test     self.logger.infoHi, this is an item page s, response.url     item  response.meta[item]     item[location]  response.xpath[iddetailsOverviewContactInfo]divspanspan[1]text.extract     item[postcode]  response.xpath[iddetailsOverviewContactInfo]divspanspan[3]text.extract        item[checkin]  response.xpath[idgoodToKnow]divdiv[2]div[2]text.extract     item[checkout]  response.xpath[idgoodToKnow]divdiv[2]div[2]text.extract     yield item codepre
Positive 43427 pIm trying to run a code on an ec2 server.  It is a python scrapy project which is executed fine on my own pc.  when trying to run it in the ec2 i get thisp  precodeTraceback most recent call last File usrlocalbinscrapy, line 4, in ltmodulegt execute File usrlocallibpython2.7sitepackagesscrapycmdline.py, line 122, in execute cmds  getcommandsdictsettings, inproject File usrlocallibpython2.7sitepackagesscrapycmdline.py, line 46, in getcommandsdict cmds  getcommandsfrommodulescrapy.commands, inproject File usrlocallibpython2.7sitepackagesscrapycmdline.py, line 29, in getcommandsfrommodule for cmd in itercommandclassesmodule File usrlocallibpython2.7sitepackagesscrapycmdline.py, line 20, in itercommandclasses for module in walkmodulesmodulename File usrlocallibpython2.7sitepackagesscrapyutilsmisc.py, line 68, in walkmodules submod  importmodulefullpath File usrlocallibpython2.7importlibinit.py, line 37, in importmodule importname File usrlocallibpython2.7sitepackagesscrapycommandsbench.py, line 3, in ltmodulegt from scrapy.tests.mockserver import MockServer File usrlocallibpython2.7sitepackagesscrapytestsmockserver.py, line 6, in ltmodulegt from twisted.internet import reactor, defer, ssl File usrlocallibpython2.7sitepackagestwistedinternetssl.py, line 59, in ltmodulegt from OpenSSL import SSL File usrlocallibpython2.7sitepackagesOpenSSLinit.py, line 8, in ltmodulegt from OpenSSL import rand, crypto, SSL File usrlocallibpython2.7sitepackagesOpenSSLrand.py, line 11, in ltmodulegt from OpenSSL.util import  File usrlocallibpython2.7sitepackagesOpenSSLutil.py, line 4, in ltmodulegt binding  Binding File usrlocallibpython2.7sitepackagescryptographyhazmatbindingsopensslbinding.py, line 87, in init self.ensureffiinitialized File usrlocallibpython2.7sitepackagescryptographyhazmatbindingsopensslbinding.py, line 106, in ensureffiinitialized librarieslibraries, File usrlocallibpython2.7sitepackagescryptographyhazmatbindingsutils.py, line 39, in buildffi ffi  cffi.FFI File usrlocallibpython2.7sitepackagescffiapi.py, line 56, in init import cffibackend as backend ImportError libffi.so.5 cannot open shared object file No such file or directory codepre  pIve tried to update ampamp reinstall all the mentioned libraries. p  pit always says it is most updated version.p  pthis is my linux distro and default python is 2.7 p  precode  cat etcrelease NAMEAmazon Linux AMI VERSION2015.03 IDamzn IDLIKErhel fedora VERSIONID2015.03 PRETTYNAMEAmazon Linux AMI 2015.03 ANSICOLOR033 CPENAMEcpeoamazonlinux2015.03ga HOMEURLhttpaws.amazon.comamazonlinuxami Amazon Linux AMI release 2015.03 codepre  pUPDATE it looks like some sort of problem in scrapy dependencies.  trying p  precode pip install scrapy  codepre  pgave me the following error p  precodecreating usrlibpython2.6distpackagescssselect error could not create usrlibpython2.6distpackagescssselect       Permission denied   Command usrbinpython2.6 c import setuptools,    tokenizefiletmppipbuild aoghBlcssselectsetup.py execcompilegetattrtokenize, open, open file.read.replacern, n, file, exec install record tmppip1Qpx2arecordinstallrecord.txt singleversionexternallymanaged compile  failed with error code 1 in tmppipbuildaoghBlcssselect codepre
Positive 43427 pScrapy will not run on my Ubuntu 14.04 giving the errorp  precodeTraceback most recent call last File usrbinscrapy, line 5, in ltmodulegt from pkgresources import loadentrypoint File usrlibpython2.7distpackagespkgresources.py, line 2749, in ltmodulegt workingset  WorkingSet.buildmaster File usrlibpython2.7distpackagespkgresources.py, line 444, in buildmaster ws.requirerequires File usrlibpython2.7distpackagespkgresources.py, line 725, in require needed  self.resolveparserequirementsrequirements File usrlibpython2.7distpackagespkgresources.py, line 628, in resolve raise DistributionNotFoundreq pkgresources.DistributionNotFound serviceidentity codepre  pTimeline I had Python 2.7.6 installed which came with Ubuntu 14.04. I upgraded to 2.7.9 which is currently my python V. I started by downloaded scrapy from the website scrapy.org following their Ubuntu instructions, and I got the error code above when attempting to use scrapy. Then I went through every imaginable stackoverflow for pip being broken, scrapy being broken but no good.p  ppip upgrade did not work a hrefhttpstackoverflow.comquestions6200056pipbrokehowtofixdistributionnotfounderrorpip broke. how to fix DistributionNotFound errorap  pThis guy had almost the same error but no response a hrefhttpstackoverflow.comquestions32088452pythonscrapyunpredictablemistakewithimportloadentrypointPythonScrapy unpredictable mistake with quotimport loadentrypointquota He pointed to a hrefhttpstackoverflow.comquestions28670554pythonscrapyissuewithscrapyversionPython amp Scrapy Issue with Scrapy versionap  pI uninstalled all scrapy and reinstalled with pip it was installing version Scrapy1.0.3 and it initially failed but I upgraded some libraries libffi amp lxml and the install worked with a sudo run. Same error remained when running scrappy.p  pAny chance anyone knows whats going on Thanksp
Positive 43427 pThis is scrapys default codeDupefiltercode class method coderequestseencodep  precodeclass RFPDupeFilterBaseDupeFilter      def requestseenself, request         fp  self.requestfingerprintrequest         if fp in self.fingerprints             return True         self.fingerprints.addfp         if self.file             self.file.writefp  os.linesep codepre  pWhile implementing a custom dupefilter. i cannot retrieve the codespidercode object from this class unlike other scrapy middlewarep  pIs there any way i can know which codespidercode object this is so i can customize it via a spider on spider basisp  pAlso i cannot just implement a middleware which reads urls and puts it into a list amp checks duplicates instead of a custom dupefilter. This is because i need to pauseresume crawls and need scrapy to store the request  fingerprint by default using the codeJOBDIRcode settingp
Negative 43427 pIn Qt, how can I convert a typed collection of objects such as a codeQListltTgtcode into a codeQListltQVariantgtcode I suppose I could construct a new list and copy the elements over, converting each to a codeQVariantcode along the way, but is there a shortcutp
Negative 43427 pI would like to create a new instance of codeFilecode from an asset in my android project.p  pI found a lot of solutions to read the file into bytes or a string, but not how to create a codejava.io.Filecode instance from it.p
Negative 43427 pMy ListBox doesnt react to my ObservableCollection.p  pThis is the ListBox I am talking about.p  precodeltListBox xNameCreateFieldsList          HorizontalAlignmentLeft          Height218          VerticalAlignmentTop          Width244          Margin0,86,0,0          BorderBrushFFB9B9B9gt     ltListBox.ItemTemplategt         ltDataTemplategt             ltGrid Margin4                   Width215                   Height32.96                   BackgroundWhitegt                 ltTextBlock TextBinding Name                            FontWeightNormal                            FontSize18.667                            Padding8,3,0,0 gt             ltGridgt         ltDataTemplategt     ltListBox.ItemTemplategt ltListBoxgt codepre  pIn my MainWindow, I prepare the data binding like thisp  precodeprivate ObservableCollectionltFieldListItemgt fieldItems  public MainWindow      InitializeComponent     fieldItems  new ObservableCollectionltFieldListItemgt     CreateFieldsList.ItemSource  fieldItems  codepre  pA FieldListItem is followingp  precodepublic class FieldListItem  ViewItem      private Field field     public string Name              get  return field.Name            public string Value              get  return field.Value            public FieldListItemField f              field  f                  codepre  pand finally the ViewItemp  precodepublic class ViewItem  INotifyPropertyChanged      private event PropertyChangedEventHandler PropertyChanged      protected void RaisePropertyChanged[CallerMemberName] string caller                if PropertyChanged  null PropertyChangedthis, new PropertyChangedEventArgscaller           The interface forces me to implement this. Why     event PropertyChangedEventHandler INotifyPropertyChanged.PropertyChanged              add           remove         codepre  pI dont know why this isnt working. Could you please helpp
Negative 43427 pNow Im developing a c project. And I dont know whats a good way of c Factorys create method. My environment is below. p  pEnvironmentp  ul ligcc 4.8.2 g li libuilt with emstdc11em optionli ul  pIve created a Item class its instances are created by MyFactoryClass.p  precodeclass Item  public   void hoge private   int fuga   string foo  codepre  pIn this case, whats a good way to implement emcreateem method In general later method is good, but Ive heard RVO in recent c. So do both ways are no problems And if there are better ways, Id love to hear your examples.p  precodestatic Item createItemint id static void createItemint id, Itemamp item codepre
Negative 43427 pWhen I am switching between Portrait to Landscape view ampVice Versa in iPad, position of my popover view gets garbled. Here is how I am calculating frame of my popover viewp  precodeaRect  self.myElement.frame aRect.origin.x  aRect.size.width  [aPopOver presentPopoverFromRectaRect inViewself.myElement.superview permittedArrowDirectionsUIPopoverArrowDirectionRight animatedYES] codepre  pPlease tell me whats wrong herep
Negative 43427 pI know that search engine bots pay attention to bold texts on the page, which are codestrongcode HTML tags. But do they still recognize if we use codefontweightboldcode instead of codestrongcode tagp  pIs the HTML codestrongcode tag equivalent to codefontweightboldcode for SEOp
Negative 43427 pI created a signup form using Bootstraps signin form example code, and Im trying to perform a crude verification on the form before the form action takes place. However, Im noticing that even though I codereturn falsecode the form action still gets submitted and I get loaded to the form action page. How can I stop this from happening emwhen the values of the form are invalidem ie email is something like codeabcdefcode.p  pHeres a fiddle a hrefhttpjsfiddle.netCCsJn1 relnofollowhttpjsfiddle.netCCsJn1ap  pNotice that even though the code returns false, the form submits.p  pSearching brought me to a hrefhttpstackoverflow.comquestions12461755preventformfromsubmittingthis questiona, but that code did not work for mep
Negative 43427 pI am using multisearch on my jqgrid to enable users search data from the server side.br My requirement is, I want to capture the search parameters specified by the user in the search grid as soon as they press the Find button.  Accordingly,br a. Is there any event that gets fired when a user clicks the Find button in the search grid b. how will I capture the search parameters specified in the search grid p  pThanks in advance.p
Negative 43427 pCurrently, when I cd re[tab][tab], bash gives me options including files and directories. Since cd only allows directories as arguments, giving me nondirectory options doesnt seem to offer any advantages. How can I modify it to only give directories as options Im using archlinux.p  precode cd re redrover.sh  research codepre
Negative 43427 pI have an interface called p  precodeISquare   codepre  pThere is a usercontrol MatrixGrid which has a public propertyp  precodepublic ListltListltISquaregtgt Squares      get  return ListltListltISquaregtgtGetValueSquaresProperty      set  SetValueSquaresProperty  codepre  pand I am able to bind to it in the designer for this usercontrol without any issue.p  pIf I place a MatrixGrid in a window and try to bind to the Squares property, the designer throws an error p  precodeThe member Squares is not recognized or accessible codepre  pand the Gui part of the designer shows p  precodeInvalid Markup, check the error list for more information codepre  pRunning the program, all the bindings work properly and everything behaves without problems.p  pIs this a bug in the designer or is there a rule written down somewhere about thisp  pIm running Visual Studio Express 2012 For Windows Desktopp  pI was able to duplicate it with the following codep  pTestControl.xaml.csp  precodepublic partial class TestControl  UserControl      public TestControl              InitializeComponent          public static DependencyProperty         TestProperty  DependencyProperty.RegisterMyTest, typeofListltListltTestgtgt, typeofTestControl     public ListltListltTestgtgt MyTest  get  return ListltListltTestgtgtGetValueTestProperty  set  SetValueTestProperty, value    public interface Test  codepre  pTestWindow.xamlp  precodeltWindow xClasssimthing.TestWindow     xmlnshttpschemas.microsoft.comwinfx2006xamlpresentation     xmlnsxhttpschemas.microsoft.comwinfx2006xaml     xmlnslocalclrnamespacesimthing     TitleTestWindow Height300 Width300gt     ltGridgt         ltlocalTestControl MyTestBinding Testsgt     ltGridgt ltWindowgt codepre
