Positive 2751 pI am comparing codeblascode with codecublascode and Im getting some mind blowing results.p  pThe cpu I am using is a codeIntelR XeonR CPU E52680 v2code at code2.8 GHzcode and I am running my matrix multiplications with codecblasdgemmcode on increasingly larger sizes of matrices.p  pThe gpu I am using is a codeNvidia K40code with 15 multiprocessors, warp size of 32, and 480 codeCUDAcode cores advertised as 2880 codeCUDAcode cores a hrefhttphttpwww.nvidia.comobjectteslaservers.html relnofollowherea. The clock speed is code0.71 GHzcode and I am using codecublasDgemmcode for matrix multiplications.p  pI have done a runtime analysis and shown that the codeK40code is code12.48code faster than the codeK80code for large matrix operations which is about what I expected. I am showing that the codeK40code is about code8000code faster than a single threaded CPU matrix dot product and this is a whole lot faster than I expected, so I suspect something is amiss.p  pNOTE I am testing with code100code iterations and averaging the runs, but I am counting emonlyem calls to the respective codegemmcode functions. I am intentionally leaving out memory allocation time on the codecpucode and codegpucode since I want to test how fast things can go emafterem the codecpucode to codegpucode data transfer has completed. Given this information, is code80xcode speedup plausible p
Positive 2751 pIve compiled OpenCv on Windows with Cuda support. Currently I dont use any Cuda function in my code. I would like to run my program on a different PC without Cuda and Im wondering if there is a possibility to use the same OpenCv dlls even without having Cuda installed. Im building with VS2013, and I tried to add the cudart6470.dll as well as all used OpenCvdlls to the delay load Dlls, but still get the same error, that this dll is missing. Thanks for any help.p
Positive 2751 pI wrote a simple program in cudac and it works on eclipse nsight. This is source codep  precodeinclude ltiostreamgt include ltstdio.hgt   global void add int a,int b, int c c  a  b   int mainvoid  int c int devc  cudaMallocvoidampdevc, sizeofint  add ltltlt1,1gtgtgt2,7,devc  cudaMemcpyampc, devc, sizeofint,cudaMemcpyDeviceToHost  printfn27 dn,c cudaFreedevc  return 0  codepre  pNow Im trying to use this code with Go language with cgo So I wrote this new codep  precodepackage main  include usrlocalcuda7.0includecuda.h include usrlocalcuda7.0includecudaruntime.h cgo LDFLAGS lcuda cgo LDFLAGS lcurand default location cgo LDFLAGS Lusrlocalcuda7.0lib64 Lusrlocalcuda7.0lib cgo CFLAGS Iusrlocalcuda7.0include             include ltstdio.hgt  global void add int a,int b, int c     c  a  b   int eseguisommavoid      int c     int devc      cudaMallocvoidampdevc, sizeofint     add ltltlt1,1gtgtgt 2,7,devc     cudaMemcpyampc, devc, sizeofint,cudaMemcpyDeviceToHost      cudaFreedevc     return c   import C import fmt  func main     fmt.Printfil risultato  d,C.eseguisomma  codepre  pBut it doesnt work I read this error messagep  precodecgocudabyexample1main.go348 error expected expression before lt token add ltltlt1,1gtgtgt 2,7,devc        codepre  pI think that I must to set nvcc cuda compiler for cgo instead of gcc. How can I do it Can I change CC environment variable best regardsp
Positive 2751 pI played a bit with the a hrefhttpdocs.nvidia.comcudacudacprogrammingguidedevicelambda relnofollowexperimental device lambdasa that where introduced in CUDA 7.5 and promoted in this a hrefhttpdevblogs.nvidia.comparallelforallnewfeaturescuda75 relnofollowblog post by Mark Harrisa.p  pFor the following example I removed a lot of stuff that is not needed to show my problem my actual implementation looks a bit nicer....p  pI tried to write a foreach function that operates either on vectors on device 1 thread per element or host serial depending on a template parameter. With this foreach function I can easily implement BLAS functions. As an example I use assigning a scalar to each component of a vector I attach the complete code in the endp  precodetemplateltbool onDevicegt void assignScalar sizet size, double vector, double a       auto assign  [] host device  sizet index   vector[index]  a      if onDevice               foreachDevice size, assign           else              foreachHost size, assign        codepre  pHowever, this code gives a compiler error because of the codehost devicecode lambdap  blockquote   pThe closure type for a lambda lambda void cannot be used in the template argument type of a global function template instantiation, unless the lambda is defined within a device or global functionp blockquote  pI get the same error if I remove the codedevicecode from the lambda expression and I get no compile error if I remove codehostcode only codedevicecode lambda, but in this case the host part is not executed...p  pIf I define the lambda as either codehostcode or codedevicecode separately, the code compiles and works as expected.p  precodetemplateltbool onDevicegt void assignScalar2 sizet size, double vector, double a       if onDevice               auto assign  [] device  sizet index   vector[index]  a          foreachDevice size, assign           else              auto assign  [] host  sizet index   vector[index]  a          foreachHost size, assign        codepre  pHowever, this introduces code duplication and actually makes the whole idea of using lambdas useless for this example.p  pIs there a way to accomplish what I want to do or is this a bug in the experimental feature Actually, defining a codehost devicecode lambda is explicitly mentioned in the first example in the a hrefhttpdocs.nvidia.comcudacudacprogrammingguidedevicelambda relnofollowprogramming guidea. Even for that simpler example just return a constant value from the lambda I couldnt find a way to use the lambda expression on both host and device.p  pHere is the full code, compile with options codestdc11 exptextendedlambdacodep  precodeinclude ltiostreamgt using namespace std  templatelttypename Operationgt void foreachHost sizet size, Operation o       for sizet i  0 i lt size i               o i         templatelttypename Operationgt global void kernelforeach Operation o       sizet index  blockIdx.x  blockDim.x  threadIdx.x     o index    templatelttypename Operationgt void foreachDevice sizet size, Operation o       sizet blocksize  32     sizet gridsize  size32     kernelforeachltltltgridsize,blocksizegtgtgt o    global void printFirstElementOnDevice double vector       printf dVector[0]  fn, vector[0]    void assignScalarHost sizet size, double vector, double a       auto assign  []  sizet index   vector[index]  a      foreachHost size, assign    void assignScalarDevice sizet size, double vector, double a       auto assign  [] device  sizet index   vector[index]  a      foreachDevice size, assign     compile error templateltbool onDevicegt void assignScalar sizet size, double vector, double a       auto assign  []  host device  sizet index   vector[index]  a      if onDevice               foreachDevice size, assign           else              foreachHost size, assign          works templateltbool onDevicegt void assignScalar2 sizet size, double vector, double a       if onDevice               auto assign  [] device  sizet index   vector[index]  a          foreachDevice size, assign           else              auto assign  [] host  sizet index   vector[index]  a          foreachHost size, assign         int main      sizet SIZE  32      double hVector  new double[SIZE]     double dVector     cudaMalloc ampdVector, SIZEsizeofdouble        clear memory     for sizet i  0 i lt SIZE i               hVector[i]  0          cudaMemcpy dVector, hVector, SIZEsizeofdouble, cudaMemcpyHostToDevice       assignScalarHost SIZE, hVector, 1.0      cout ltlt hVector[0]   ltlt hVector[0] ltlt endl      assignScalarDevice SIZE, dVector, 2.0      printFirstElementOnDeviceltltlt1,1gtgtgt dVector      cudaDeviceSynchronize      assignScalar2ltfalsegt SIZE, hVector, 3.0      cout ltlt hVector[0]   ltlt hVector[0] ltlt endl      assignScalar2lttruegt SIZE, dVector, 4.0      printFirstElementOnDeviceltltlt1,1gtgtgt dVector      cudaDeviceSynchronize    assignScalarltfalsegt SIZE, hVector, 5.0    cout ltlt hVector[0]   ltlt hVector[0] ltlt endl    assignScalarlttruegt SIZE, dVector, 6.0    printFirstElementOnDeviceltltlt1,1gtgtgt dVector    cudaDeviceSynchronize      cudaErrort error  cudaGetLastError     iferrorcudaSuccess              cout ltlt ERROR  ltlt cudaGetErrorStringerror       codepre  pI used the production release of CUDA 7.5.p  pstrongUpdatestrongp  pI tried this third version for the assignScalar functionp  precodetemplateltbool onDevicegt void assignScalar3 sizet size, double vector, double a   ifdef CUDAARCH define LAMBDAHOSTDEVICE device else define LAMBDAHOSTDEVICE host endif      auto assign  [] LAMBDAHOSTDEVICE  sizet index   vector[index]  a      if onDevice               foreachDevice size, assign           else              foreachHost size, assign        codepre  pIt compiles and runs without error, but the device version codeassignScalar3lttruegtcode is not executed. Actually, I thought that codeCUDAARCHcode will always be undefined since the function is not codedevicecode but I checked explicitly that there is a compile path where it is defined.p
Positive 2751 pHere is a simplified version of my code.p  precodeglobal kernelfloat array, const float factors     int i  threadIdx.x     sharedvariable factor     if i  0 factor  factors[blockIdx.x]     synchthreads      if i  0 printfarray[0] f, array[i]     array[i]  factor     if i  0 printfarray[0] f, array[i]   int main      initialize cud resources      int N10     float array, factors     cudaMallocamparray, Nsizeoffloat     cudaMallocampfactors, 1sizeoffloat      for i0 to 9, set array[i] to 10      set factors to appropriate 1 value     kernelltltlt1,Ngtgtgtarray, factors     cudaDeviceSynchronize       release array, factors, cuda resources  codepre  pThe expected result is as followp  precodearray[0] 1.0e1 array[0] 9.0e0 codepre  pI got an unexpected result, however, something likep  precodearray[0] 0.0000002 array[0] 0.9999998 codepre  pI wonder is there any reason for this unexpected result. Any suggestioncomment is welcome, though Im afraid that the simplification is too much.p
Positive 2751 pIm using CUDA via PInvoke in .NET. In CUDA, they provide a special memory allocation method, which can allocate memory on GPU while in the same time, you can access them from host of course, unmanaged memory from .NET perspective. This is called unified memory of CUDA which blur the board between CPU and GPU memory.p  pSo, is it possible to alter the default .NET array memory allocation method to a customized unmanaged memory allocation In that array, I only need to store very simple primitive types such as int, double.p  pFor example, in CUDA C, they override the codenewcode operator to make that class to be seen from both CPU and GPUp  precodeclass Managed  public   void operator newsizet len      void ptr     cudaMallocManagedampptr, len     cudaDeviceSynchronize     return ptr       void operator deletevoid ptr      cudaDeviceSynchronize     cudaFreeptr     codepre
Positive 2751 pI was wondering what the fastest way of computing a sparse matrixvector product y  Ax in CUDA on multiple let say n GPUs is. p  pMy naive approach would be to divide the vector x and y into n chunks, 1 chunk on each GPU. Then also split up the matrix A in smaller n2 blocks Aij and computing p  precodeyi  sumj Ai,j xj,  GPU j stores Ai,j and xj, result is copied                             to and summed up on GPU i  codepre  pon the different GPUs j1..n with lets say cuSPARSE. Would this work With the unified memory architecture, in principle all GPUs should be able to access the global memory.p  pIs the memory transfer between the GPUs going to be incredibly slow I dont expect a large speed up but I was wondering if it is going to be slower than doing the matrixvector multiplication on 1 single GPU.p
Positive 2751 pI have number of image tiles as input to the series of CUDA kernels. In this execution chain, output of one step is used as input for the further steps, without copying back the intermediate output in the host memory. p  precodecudaKernel1inputImage, out1, stream cudaKernel2out1, out2, stream cudaKernel3out2, out3, stream .... cudaKernelN..., ..., stream codepre  pBut for a certain scenario I have to include codeifelsecode condition in the execution chain, for which I have to copy back the result to the host memory. p  precodecudaKernel1inputImage, output1, stream cudaKernel2out1, out2, stream cudaKernel3out2, out3, stream .... cudaKernel11out10, out11,stream  copyDtoHAsynctemp,out11, stream  cuStreamSynchronizestream  ifSOMECONDITIONONtemp       cudaKernel12out11, out12, stream     cudaKernel13out12, out13, stream     cudaKernel14out13, out14, stream     .........  codepre  pIn the above scenario the codecopyDtoHAsynccode, codecuStreamSynchronizecode and codeifcode calls are the stream blocking calls. p  pSuppose I have 100 input tiles given as input and getting executed on multiple GPU streams simultaneously. for 40 tiles if condition is true, for remaining 60 it is false. What is the BEST way to manage such intermediate blocking calls How can I ensure uninterrupted execution of those 40 tiles on GPU without getting blocked because of those blocking callsp  pAny post, similar problem, relevant examples will be appreciated. p
Positive 2751 pI have a PC Windows 7 x64 with 2 Nvidia GPUs on it, a Tesla and a Gforce. p  pThe idea of having both is to be able to use the Tesla for computing, and the Gforce for the screenopenGL stuff that the computer may need. p  pHowever, whenever I have run some CUDA code, I cannot access anything that has webGL on the web using chrome , as my webGL is unavailable checked accesing a hrefhttpchromegpu relnofollowchromegpua. This only happens after running CUDA code. p  pThe code I am  using is called by Matlab mex, but does not use any other Matlab functionality, just codemexErrMsgIdAndTxtcode and some other codeiocode code to wrap between Matlab and C. In my code I have the following code to select the correct graphic cardp  precode int deviceCount  0     cudaGetDeviceCountampdeviceCount      if deviceCount  0              mexErrMsgIdAndTxtCBCTCUDAAxcudaGetDeviceCount,No CUDA enabled NVIDIA GPUs found          bool foundfalse     for int dev  0 dev lt deviceCount dev              cudaSetDevicedev         cudaDeviceProp deviceProp         cudaGetDevicePropertiesampdeviceProp, dev          if strcmpdeviceProp.name, Tesla K40c  0             foundtrue             break                   if found         mexErrMsgIdAndTxtCBCTCUDAAxcudaDevice,No Tesla K40c found codepre  pand when the code ends I callp  precode cudaDeviceReset codepre  pI was under the impression wrong one of course that this piece of code would make sure that the Gforce was free for the PC to use, but it isnt.p  pWhy is this happening What should I add in my code to make sure the Gforce is free to use for the computerp
Positive 2751 pI am trying to use GNU decimal floats with NVCC  and I get the following errorp  precodeusrincludec4.8decimaldecimal230 error invalid argument to attribute mode codepre  pThe affected line is the followingp  precodetypedef float decfloat32 attributemodeSD codepre  pI assume that NVCC does not support SD as an argument for mode. Is there any workaround or it is just not possible with NVCC The code works well when compiling for CPU.p  pHowwhere is this SD defined p  pThanksp  hr  pUpdate I could find where SD is defined for GCC. Two great answers herep  pa hrefhttpstackoverflow.comquestions4559025whatdoesgccattributemodexxactuallydoWhat does GCC attributemodeXX actually doap  pFor GCC gccgccmachmode.defp  precode Decimal floating point modes.    DECIMALFLOATMODE SD, 4, decimalsingleformat DECIMALFLOATMODE DD, 8, decimaldoubleformat DECIMALFLOATMODE TD, 16, decimalquadformat codepre  pIsolating the host code in a .cpp file works ok. Once the code goes into a .cu, NVCC is used and it doesnt compile anymore. I can keep devicehost code  apart but I was investigating how the GCC decimal library works internally in combination with NVCC.p  pWhere can I find more information about NVCC connected to thisp
Negative 2751 pRight now Im using celery to handle my deployment scriptfabric. So I need to save every project deployment log to database, then later I can check whether the deployment run perfectly or not. However I still havent found the right way to save each task log and a little bit confused about using the celery logger. Im using celery 2.5.1p  pviews.py p  precodedef deployrequest, projectslug     project  getobjector404Project, slugprojectslug     deploysettings  simplejson.loadsproject.result settings in json format     tasks.deploy.delaydeploysettings codepre  ptasks.pyp  precodefrom celery.task import task from deployer import fabfile  task def deploydeploysettings     logger  deploy.getlogger     fabfile.deploysettings  deploysettings     fabfile.clone    run the deployment script, I need to save all the output message      return True codepre  pfabfile.pyp  precodeenv.hoststring  exampleexample.com env.password  example deploysettings    def clone     with cddeploysettings[PATHTOAPPS]         runmkdir s  deploysettings[PROJECTSLUG]         rungit clone s s  deploysettings[URL], deploysettings[PROJECTSLUG]         with cdsexample  deploysettings[PROJECTSLUG]             rungit checkout s  deploysettings[BRANCH] codepre
Negative 2751 pWere using autofac and I noticed the RegisterComponent method off of ContainerBuilder.  I couldnt find any examples of its usuage, is this meant to be used by client code  If so, any examples on how to use itp
Negative 2751 pI am trying to use PFIncrementalStore, a hrefhttpsbonami.github.ioPFIncrementalStore relnofollowhttpsbonami.github.ioPFIncrementalStoreap  pAfter setting up as instruction, I get the following error at [context performBlock,p  precode Terminating app due to uncaught exception NSInvalidArgumentException, reason Can only use performBlock on an NSManagedObjectContext that was created with a queue. codepre  pSome internet search said, NSManagedObjectContext must be created with NSPrivateQueueConcurrencyType.p  pIf I look up all NSManagedObjectContext init in PFIncrementalStore.m, I get two occurrence of p  precodebackingManagedObjectContext  [[NSManagedObjectContext alloc]     initWithConcurrencyTypeNSPrivateQueueConcurrencyType] NSManagedObjectContext childContext  [[NSManagedObjectContext alloc] initWithConcurrencyTypeNSPrivateQueueConcurrencyType] codepre  pWhy am I getting that error  How should I edit PFIncrementalStore  Thanks.p
Negative 2751 pI have a problem with Xcodes organizer. Whenever I click on it to launch it everything freezes. I have to force quit Xcode and expensive bash process.p  pI tried top  ol liRestart MACli liReinstall Xcodeli liKill bash process many times while loading Organizerli liFollowed a hrefhttpstackoverflow.comquestions5714372howtoemptycachesandcleanalltargetsxcode462470736247073How to Empty Caches and Clean All Targets Xcode 4ali ol  pI tried practically everything I found about it here, but nothing worked. Ive seen similar questions here, but people usually had problem with already working Organizer and the things from list above helped them.p  pAny ideas what I could do about itp  pThanks in advance.p
Negative 2751 pI am trying to track my BackgroundWorker threads as described in a hrefhttpdevpinoy.orgblogsjakelitearchive200901105tipsondebuggingmultithreadedcodeinvisualstudionet.aspx relnofollowthis articlea the Threads Debug Windows is emptyp  pimg srchttpi.stack.imgur.comT0RB6.png altenter image description herep  pAnd yes, a hrefhttpstackoverflow.coma799551869501Im debugginga.p  pWhat am I missingp
Negative 2751 pIm running a webapp on heroku, and when I try and log in using strongPython Social OAuthstrong through google I get a Server Error 500. p  pThe default url is a hrefhttpskloudtransfer.herokuapp.com relnofollowhttpskloudtransfer.herokuapp.coma and when I try and complete the authentication I am lead to strongkloudtransfer.herokuapp.comcompletegoogleplusstrong. p  pIm supposed to be led to strongkloudtransfer.herokuapp.commembersstrong, as is listed in my site.py. strongMy repo is here a hrefhttpsgithub.comlilshimkloudtransfer relnofollowhttpsgithub.comlilshimkloudtransferastrongp  pHere is the heroku logs for the 500 errorp  precode20150108T002700.2542530000 heroku[router] atinfo methodPOST pathcompletegoogleplus hostkloudtransfer.herokuapp.com requestidfdda74484fca49878d5facddbd993b70 fwd76.219.245.151 dynoweb.1 connect1ms service473ms status500 bytes253 codepre
Negative 2751 pIm building a communications system using tcpip. Im using .NET, C and VS2012.p  pThose systems exchange metada between them. The basic message contains the metadata name and its value the data itself. One system doesnt know the other system datatypes. p  pThe message has the following struct FromNode, ToNode, MetadataName, MetadataType, MetadataSizeInBytes, MetadataValue. All messages are pure byte[] with delimited fields not serialized, as some systems can be Unix flavoured.p  pWhen receiving that message I would like to associate the metadata to a real variable, based on its type. So I built the following classp  ppublic class RealMetadatap  precode          public string Type  get set           public Type   Value  get set  ltlt Ive tried var and object, with no success.  codepre  pLater on code I wanna access the real value of Metadatap  precodeif Type  INTEGER       int RealValue  int Value if Type  STRING       string RealValue       Buffer.Blockcopy RealValue, 0, Value, 0, MetadataSizeInValues  sizeof char if Type  FLOAT       float RealValue  float Value codepre  pThis whole thing sometimes dont compile or doesnt work at runtime. I dont know exactly what type Value shall be declared on the class property, and how to get its data to a real variable.p  pThanks a lot for any idea or suggestion.p  pRdsp
Negative 2751 pI want to create a button background, which is exactly the same as attrselectableItemBackground but with a black stroke outline.p  pIs there a way to extend attrselectableItemBackground and add a black outline or will I have to create a completely new stateListp
Negative 2751 pEngineering incredibly large webapps, do we have any top or limit or best practice for filesizes in these large projects The biggest I have seen is probably twittergmail which had around 1mb Minified javascript  but how much can a browser handlep  pWhat if there is a large app with 5mb, 10mb or 100mb javascript minified When does it severely affect performance or memory usage Even if the app is very well written and optimized  can the jit handler take whatever Are there any diminishing returnsp  pIs there any real example of apps beeing this big, except for the usual suspects such as gmail, twitter, facebook, googledocs, etc.p  pThanksp
Negative 2751 pI always get this error when I try to use the ipsRegistry class.p  pcodeFatal error Class ipsRegistry not found in pathinfo.php on line 4codep  pI have no idea why this is happening.p  pinfo.phpp  precodeltphp requireonce httpwebsite.comforuminitdata.php  requireonce httpwebsite.comforumadminsourcesbaseipsRegistry.php  registry  ipsRegistryinstance registrygtinit   Fetch member details member  registrygtmembergtfetchMemberData   Print the display name print member[membersdisplayname] gt codepre  pipsRegistery.php contains the classp  precodeltphp    ltpregt   Invision Power Services   IP.Board v3.4.6   ipsRegistry Registry file controlls handling of objects needed throughout IPB   Last Updated Date 20131016 125741 0400 Wed, 16 Oct 2013    ltpregt     author      Author AndyMillne    copyright   c 2001  2009 Invision Power Services, Inc.   license     httpwww.invisionpower.comcompanystandards.phplicense   package     IP.Board   link        httpwww.invisionpower.com   since       Tue. 17th August 2004   version     Rev 12380       Base registry class  class ipsRegistry             Holds instance of registry singleton implementation             var     object           private static instance             Registry initialized yet             var     boolean           private static initiated  FALSE             SEO templates             var     array           protected static seoTemplates  array             Incoming URI  used in SEO  fURL stuffs             var     string           protected static uri               Flag to note incorrect FURL no furl template match             var     string           protected static noFurlMatch  false             Holds data for app  coreVariables             var     array           protected static coreVariables             array     protected static masterCoreVariables   array                  Handles for other singletons             var     array           protected static handles                    array codepre  pThe file itself is very long, and the code above is just a snippet. How can I fix this issue Is it a problem with the file pathp
