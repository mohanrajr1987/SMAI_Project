<p>I'm not well versed in MATLAB and was curious about how it handles dynamic memory allocation <em>under the hood</em>?</p>  <p>One primary method is to allocate large chunks and more than is necessary so that you don't have to allocate for each new element added. In doing a bit of research, I saw a lot of people who personally managed their own large-chunk allocation (assuming they didn't know their final size) or did things like creating a maximum size, then trimming. An example is <a href="http://undocumentedmatlab.com/blog/array-resizing-performance" rel="nofollow">Undocumented MATLAB</a> which advises you to perform block memory allocation yourself. I would have thought that a language like MATLAB would know to do it itself and I wouldn't be required to concern myself with issues like that. This implies to me if you try to append a single new element on to an array, MATLAB allocates new memory for only that single element, which is horribly inefficient.</p>  <p>My question is two-fold</p>  <ul> <li>For dynamic arrays, does MATLAB allocate in large chunks, and more memory than is necessary to save on computational efficiency, or does it allocate memory for only what is being concatenated?</li> <li>If the former is the the case, is there a reason MATLAB chose to go with this design?</li> </ul>