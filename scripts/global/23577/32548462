<p>Consider this code:</p>  <pre><code>NSString * coordinateString = [NSString stringWithFormat:@"(%@,%@}", [inPoint objectAtIndex:0],[inPoint objectAtIndex:1]]; CLLocationCoordinate2D  * myPoint= (__bridge CLLocationCoordinate2D *)(coordinateString); </code></pre>  <p>My question is: In this example the value of </p>  <pre><code>[inPoint objectAtIndex:0] and [inPoint objectAtIndex:0] </code></pre>  <p>are respectively 16.4006 and 38.254</p>  <p>If I log the value of myPoint, I get "myPoint=(16.400583,38.254028}". Just as a I expected. However, in the Debug Panel, myPoint is represented with a latitude of 7304.....-304 and a longitude of endless zeroes.</p>  <p>Is this an internal representation, or is something lost in translation from double to NSString to CLLocationCoordinate2D?</p>