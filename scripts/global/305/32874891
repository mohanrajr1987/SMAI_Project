<p>I have a fraction part of a float number (5 of -10.5, for instance). It is a character since I extracted it from the input. How can I convert that character into a binary fraction part of that float number? (I am building a float input -> HEX output in 32bit IEEE784, I have already extracted binary representations of the sign, exponent and integer part of mantissa.)</p>  <p>I have been thinking about implement the algorithm of multiplying the fraction by two and taking the remainder, then repeating till it fill the mantissa, but I am not allowed to use any floating point operations in an assignment.</p>  <p>Examples: User inputs -10.5. The program needs to take the fraction of the number (which is 5) and convert it to binary format (which is 1 (.1))</p>