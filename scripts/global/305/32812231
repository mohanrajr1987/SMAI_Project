<p>In single point precision there is a significand of 23 bits giving an integer range (if we where only storing a discreet integer value) up to 2^24. The exponent is 8 bits giving a range up to 2^127. At large magnitude numbers there is a point where they start to lose significant digits from the significand/mantissa.</p>  <p>This means a number like (2^32 + 2^8):<br> 4,294,967,552<br> 0x100000100<br> 0b100000000000000000000000100000000<br> would be stored simply as:<br> exponent 0b00100000<br> significand / mantissa 0b00000000000000000000000 (1 impled bit)<br> and lose 256 from its precision.</p>  <p>This seems to be the opposite of so called 'sub-normal' numbers. Essentially the range of numbers being stored as an integer in the significand is much smaller than the range of numbers capable of being stored when taking into account the exponent. So once you get to 2^24 you start to lose information (possible I have misundestanding of standard)! This seems to be the opposite of what happens at the subnormal range when information is lost when there is a significand but with a smaller exponent than 2^-127</p>  <p>Have I missed something in my understanding of the IEEE754 standard?<br> If not what is this scenario called when large magnitude numbers lose precision (which seems to be the opposite of subnormal, perhaps 'supernormal')?<br> And to maintain precision should I limit all floating point numbers to -(10^7) &lt; x &lt; 10^7 ?  </p>  <p>EDIT  Updated the numbers from 100,000,010, I also added more language to explain my understanding.</p>  <p>EDIT 2 @Weather Vane and is correct. The point of floating point precision is that it loses accuracy on a fractional scale as soon as we start increasing magnitude, this starts affecting the integer scale when the magnitude increases the radix point past the end of the significand<br> 0.0000000000000000000001 ->-> 10000000000000000000000.0  I can see why the exponent is so much larger than the significand for representing ultra small numbers to the largest precision possible, but for large magnitude numbers there seems to be a whole class of numbers that lose information at a greater than fractional scale once we go beyond 23 sig fig in binay. I want to know what these are called, if they even have a name e.g. 'super normal'?</p>