<p>First of all I apologize for the vague title, but the problem is that I'm not sure what is causing the error.</p>  <p>I'm using Python to extrapolate some data from a website. The code I created works perfectly when passing one link at the time, but somehow breaks when trying to collect the data from the 8000 pages I have (it actually breaks way before). The process I need to do is this:</p>  <ol> <li>Collect all the links from one single page (8000 links)</li> <li>From each link extrapolate another link contained in an iframe</li> <li>Scrape the date from the link in 2.</li> </ol>  <p>Point 1 is easy and works fine. Point 2 and 3 works for a while and then I get some errors. Every time at a different point and it's never the same. After some tests, I decided to try a different approach and run my code until point 2 on all the links in 1, trying to collect all the links first. And at this point I found out that, probably, I get the error during this stage. The code works like this: in a for cycle I pass each item of a list of urls to the function below. It's supposed to search for a link to the Disqus website. There should be only one link and there is always one link. Because with a library as lxml, it's not possible to scan inside the iframe, I use selenium and the ChromeDriver.</p>  <pre><code>def get_url(webpage_url):     chrome_driver_path= '/Applications/chromedriver'      driver = webdriver.Chrome(chrome_driver_path)      driver.get(webpage_url)     iframes=driver.find_elements_by_tag_name("iframe")     list_urls=[]     urls=[]      # collects all the urls of all the iframe tags     for iframe in iframes:         driver.switch_to_frame(iframe)         time.sleep(3)         list_urls.append(driver.current_url)         driver.switch_to_default_content()     driver.quit()      for item in list_urls:         if item.startswith('http://disqus'):             urls.append(item)      if len(urls)&gt;1:         print "too many urls collected in iframes"     else:         url=urls[0]      return url </code></pre>  <p>At the beginning there was no time.sleep and it worked for roughly 30 links. Then I put a time.sleep(2) and it arrived to about 60. Now with time.sleep(3) it works for around 130 links. Of course, this cannot be a solution. The error I get now, it's always the same (index out of range in url=urls[0]), but each time with a different link. If I check my code with the single link where it breaks, the code works, so it can actually find urls there. And of course, sometimes passes a link where it stopped before and it works with no issue. I suspect I get this because maybe of a time-out, but of course I'm not sure.</p>  <p>So, how can I understand what's the issue, here?</p>  <p>If the problem is that it makes too many requests (even though the sleep), how can I deal with this?</p>  <p>Thank you.</p>