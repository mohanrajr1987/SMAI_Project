<p>the main question is the one above (learning is cool), but the ultimate goal is to find out more about the orientation matrix.  I'm trying to put the lat and long values (possibly altitude) of a location object into a float[3].  The way I see it is; it may be accepted into the RotationMatrix. I'm not too sure if the second float value is even adding to the overall angle (I think it is because you can leave it as null) but I'm just trying to rule out some logic. any feedback is appreciated :)  Here is the code.</p>  <pre><code>  public void onSensorChanged(SensorEvent event) {     //just pretend they are actual co-ordinates     target.setLongitude(0.0);     target.setLatitude(-0.0);     //the broken bit     float[] rTarget = new float []{target.longitude,target.Latitude,target.altitude?};      if (event.sensor == mAccelerometer) {         System.arraycopy(event.values, 0, mLastAccelerometer,  0,   event.values.length);         mLastAccelerometerSet = true;     } else if (event.sensor == mMagnetometer) {         System.arraycopy(event.values, 0, mLastMagnetometer,  0, event.values.length);         mLastMagnetometerSet = true;     }     if (mLastAccelerometerSet &amp;&amp; mLastMagnetometerSet) {         //I need the rTarget to go here possibly?         SensorManager.getRotationMatrix(mR, rTarget ,  mLastAccelerometer, mLastMagnetometer);         SensorManager.getOrientation(mR, mOrientation); </code></pre>