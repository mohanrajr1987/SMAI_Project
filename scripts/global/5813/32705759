<p>I have a <code>.zip</code> on Amazon S3 that contains a single <code>.csv</code>. I want to place the uncompressed <code>.csv</code> on S3 using constant memory/disk space, even if the file is very large, so I want to use a program that can unzip from stdin and stream to stdout. Since my <code>.zip</code> contains only one file, <code>funzip</code> seems suitable. I'm also using <code>s3cmd</code> because it's simple, familiar, and supports the standard streams and multipart uploads for large files out of the box.</p>  <p>When I try to chain the three tasks together it fails:</p>  <pre><code>$ s3cmd get s3://bucket/file.csv.zip - | funzip | s3cmd put - s3://bucket/file.csv &lt;stdin&gt; -&gt; s3://bucket/file.csv  [part 1, 15MB]  15728640 of 15728640   100% in  342s    44.79 kB/s  done ERROR: [Errno 54] Connection reset by peer funzip error: invalid compressed data--format violated &lt;stdin&gt; -&gt; s3://bucket/file.csv  [part 2, 2MB]  2818048 of 2818048   100% in   74s    37.07 kB/s  done </code></pre>  <p>This happens consistently. It looks like the pipeline somehow kills the download midway, always at the same point. But if I split it up and store results in an intermediary file with commands such as:</p>  <pre><code>$ s3cmd get s3://bucket/file.csv.zip - | funzip &gt; test.csv WARNING: MD5 signatures do not match: computed=b11f08d4e8ef4553b51ed762b3d6c890, received="a420b637634e63ebbdca36f4f389ef9b-2"  $ cat test.csv.zip | funzip | s3cmd put - s3://bucket/file.csv &lt;stdin&gt; -&gt; s3://bucket/file.csv  [part 1, 15MB]  15728640 of 15728640   100% in  399s    38.47 kB/s  done &lt;stdin&gt; -&gt; s3://bucket/file.csv  [part 2, 15MB]  15728640 of 15728640   100% in  378s    40.59 kB/s  done &lt;stdin&gt; -&gt; s3://bucket/file.csv  [part 3, 11MB]  11586401 of 11586401   100% in  281s    40.13 kB/s  done </code></pre>  <p>it works fine (the two commands above aren't meant to be two halves of the original, since they both use <code>funzip</code> - I just wanted to demonstrate that <code>funzip</code> and <code>s3cmd</code> with stdin/stdout aren't necessarily enemies). I doubt that the MD5 warning has anything to do with this as the files look fine.</p>  <p>If I replace <code>s3cmd get/put</code> with <code>aws s3 cp</code> the complete chain works. I'm really just curious as to what could be causing the pipeline with <code>s3cmd</code> to fail.</p>  <p>I considered that perhaps the <code>put</code> at the end was too slow and caused the <code>get</code> to time out after the pipe buffer filled up or something, so I tried inserting the below python script in the middle of each of the two commands that succeeded to slow things down. It didn't cause any failure.</p>  <pre><code>import sys import time for line in sys.stdin:     time.sleep(1)     print line </code></pre>