<p>I'm working on a project about lung cancer classification by using mutated genes. Now that my data contains 1302 samples and 664 genes. All genes are considered as a binary feature of a sample. The data contains 3 types lung cancer A, B and C and A:B:C is about 8:3:1.</p>  <p>I have implement several classifiers, GBDT, Random Forest, Naive Bayes but all the classifiers come out with the similar result, the accuracy is about 0.60 and about 90% samples were reclassified to classA by the classifier. Are there any ways to improve the classfier?  Appreciate for any help.</p>  <hr>  <p>The genes are from the gene panel of my company, I try to select some genes by feature selection method rather than use all genes from the panel, but it still didn't work. I also have tried tweak the parameter and the result is  the same. Here is a part of my data(Don't have enough reputation to post images).</p>  <pre><code>                        Sample  Class  AACS  ABCB1  ABCC1  ABCC2  ABCC3                                                     \                            WG06T      1     0      0      0      0      0         TCGA-55-A4DG-01A-11D-A24D-08      1     0      0      0      0      0      TCGA-93-A4JO-01A-21D-A24P-08      1     0      0      0      0      0                             25D-T      2     0      0      0      0      0      TCGA-66-2754-01A-01D-0983-08      2     0      0      0      0      0      TCGA-MP-A4T4-01A-11D-A25L-08      1     0      0      0      0      0      TCGA-55-8091-01A-11D-2238-08      1     0      0      0      0      0      TCGA-73-7499-01A-11D-2184-08      1     0      0      0      0      0      TCGA-39-5027-01A-21D-1817-08      2     0      0      0      0      0                             KU-5T      2     0      0      0      0      0      TCGA-NJ-A4YP-01A-11D-A25L-08      1     0      0      0      0      1    </code></pre>  <p>A small part of my data, the 'Class' column refers to the lung cancer type, the 'Sample' column refers to the patient, and the other columns are genes</p>  <p>My python code of GBDT classifier</p>  <pre><code>import numpy as np import pandas as pd import xgboost as xgb from sklearn import cross_validation from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import chi2   data = pd.read_csv('SamplePanelDataTotal.csv', header = 0) data = data.ix[np.random.permutation(data.index)]   sub_X = data.iloc[:, 2:] sub_y = data.iloc[:, 1] test_df = data.iloc[:, [0,1]] sub_X_new = pd.DataFrame(SelectKBest(chi2, k = 150).fit_transform(sub_X,    sub_y)).T   loo = cross_validation.KFold(sub_X_new.shape[1], n_folds = 10) predictions = [] i = 0 for train_index, test_index in loo:     print train_index,'\t',test_index     i += 1     train_X, test_X, train_y = sub_X_new[train_index].T.as_matrix(),    sub_X_new[test_index].T.as_matrix(),\                            sub_y[train_index]     gbm = xgb.XGBClassifier(max_depth = 3, n_estimators = 300,                         learning_rate = 0.05).fit(train_X, train_y)     sprediction = gbm.predict(test_X)     predictions.append(sprediction)     print i   predictions = [i for sl in predictions for i in sl] phen = pd.DataFrame({'Sample':data['Sample'],                  'Class':predictions}, columns= ['Sample', 'Class'])   test_df.to_csv('TotalTestData_cv.csv', index = False) phen.to_csv('Totalpredict_cv.csv', index = False) </code></pre>