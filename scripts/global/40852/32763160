<p>My DataFlow pipeline starts with a <code>BatchBlock</code> and several Tasks are posting items into this <code>BatchBlock</code>. Now, this <code>BatchBlock</code>propagates data to the next block depending on a Timer with the help of the <code>TriggerBatch()</code> method.</p>  <p>In this case, you can assume that none of the batches are of the (very high) batch size provided during the creation of the <code>BatchBlock</code> i.e. each triggered batch could be of a different size. </p>  <p>Just before triggering the <code>BatchBlock</code> I would like to remove all duplicate items present in the batch that is about to be propagated to the next block in the pipeline. Is there a way I can do that?</p>