<p>I am trying to read data from redshift to spark 1.5 using scala 2.10</p>  <p>I have built the spark-redshift package and added the amazon JDBC connector to the project, but I keep getting this error:</p>  <pre><code>Exception in thread "main" java.lang.NoClassDefFoundError: com/amazonaws/auth/AWSCredentials </code></pre>  <p>I have authenticated in the following way:</p>  <pre><code>val hadoopConf = sc.hadoopConfiguration hadoopConf.set("fs.s3n.impl","org.apache.hadoop.fs.s3native.NativeS3FileSystem") hadoopConf.set("fs.s3n.awsAccessKeyId", "ACCESSKEY") hadoopConf.set("fs.s3n.awsSecretAccessKey","SECRETACCESSKEY")  val df: DataFrame = sqlContext.read.format("com.databricks.spark.redshift") .option("url","jdbc:redshift://AWS_SERVER:5439/warehouseuser=USER&amp;password=PWD") .option("dbtable", "fact_time") .option("tempdir", "s3n://bucket/path") .load()  df.show() </code></pre>