<p>I was looking at some assembly code and came across the following (which I've converted for ease of the reader).  All registers are 8 bits, and pointers are 16 bits.  So <code>(q)</code> loads 8 bits.</p>  <p><code>(q+1) = (q+1) = rr(q+1)</code> where <code>(q)</code> dereferences <code>q</code> and <code>rr(q)</code> is rotate right <code>(q) = (q) + (q)/2 + bit((q+1), 0)</code> where <code>bit((q+1), 0)</code> is getting the 0th bit of <code>(q+1)</code></p>  <p>This really confused me, because what the above code does is multiply a 16 bit value by 1.5, regardless of its endianness (i.e. however you interpret q be it little endian or big endian, its value is multiplied by 1.5 in its respective endian).</p>  <p>I'm confused about how they're going about multiplying a 16 bit value by 1.5 using two 8 bit values.  Whats going on here? Specifically, what is the purpose of adding the 0th bit of <code>(q+1) to (q)</code> and the purpose of rotating <code>(q+1)</code> to the right?</p>  <p>Here is the assembly code:</p>  <pre><code>ld a, (q) ld b, a ld a, (q+1) ld c, a srl b rr c add c ld (q+1), a ld a, (q) adc b ld (q), a ret </code></pre>