<p>I am currently looking at different alternatives to improve the performance of a search operations for a existing web application. I am attempting to figure out what would be the available maximum improvement possible for the existing system with compression before looking at different alternatives.</p>  <p>In the existing system a result set returned in response to a user search is formulated using internal as well as external data resources. The result set is made of of nested Java collection objects. I would like to compress and transfer objects and decompress them as and when required. The data we want to compress is quite varied, from float vectors to strings to dates. </p>  <p>I have tried out a Java utility to compress and expand a collection object. I tried out the below code block in an attempt to check how Java compression would help reduce the the result set size and if it would improve data transfer over the network. I have used the Gzip based compression.</p>  <pre><code>package com.soft.java.Objectcompress;  import java.io.ByteArrayInputStream; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.io.Serializable; import java.util.zip.GZIPInputStream; import java.util.zip.GZIPOutputStream; import java.io.InputStream; import java.io.OutputStream;  /**  *   * The Class ObjectCompressionUtil.  *   * @param &lt;T&gt; the generic type of the serializable object to be compressed  */ public class ObjectCompressionUtil&lt;T extends Serializable&gt; {      /**      * The compressObject(final T objectToCompress) takes the object       * to compress and returns the compressed object as byte array.      *       * @param objectToCompress the object to compress      * @return the compressed object as byte array      * @throws IOException Signals that an I/O exception has occurred.      */     public byte[] compressObject(final T objectToCompress) throws IOException {          ByteArrayOutputStream baos = new ByteArrayOutputStream();         /*Create a new GZIPOutputStream with a default buffer size.*/         final GZIPOutputStream gz = new GZIPOutputStream(baos);         /*Create an ObjectOutputStream that writes to the specified GZIPOutputStream.*/          final ObjectOutputStream oos = new ObjectOutputStream(gz);          try {           /*Writes the specified object to be compressed to the ObjectOutputStream and flush it, using writeObject(Object obj)*/             oos.writeObject(objectToCompress);           /*flush() API methods of ObjectOutputStream*/             oos.flush();         }         catch (Exception e) {             e.printStackTrace();         }         /*Closes both the GZIPOutputStream and the ObjectOutputStream, using their close() API methods.*/         finally {             oos.close();         }          byte[] bytes = baos.toByteArray();          return bytes;     }      /**      * The expandObject(final T objectToExpand, final InputStream instream) method takes       * the object to expand and an InputStream and returns the expanded object.      *       * @param objectToExpand the object to expand      * @param instream the input stream      * @return the expanded object      * @throws IOException Signals that an I/O exception has occurred.      * @throws ClassNotFoundException the class not found exception      */     public T expandObject(byte[] objectToExpand) throws IOException,ClassNotFoundException {         ByteArrayInputStream bais = new ByteArrayInputStream(objectToExpand);       /*Creates a new GZIPInputStream with a default buffer size.*/         final GZIPInputStream gs = new GZIPInputStream(bais);       /*Creates an ObjectInputStream that reads from the specified GZIPInputStream.*/         final ObjectInputStream ois = new ObjectInputStream(gs);          /*Reads the object to expand from the ObjectInputStream, with readObject() API method of ObjectInputStream.*/         try {             @SuppressWarnings("unchecked")             T expandedObject = (T) ois.readObject();             //MyObject myObj1 = (MyObject) objectIn.readObject();              /*Returns the expanded object*/             return expandedObject;         } finally {             /*Closes both the GZIPInputStream and the ObjectInputStream, using their close() API methods.*/             gs.close();             ois.close();             bais.close();         }     } } </code></pre>  <p>I also checked for similar problems on this forum and there were a few but did not explicitly answer my question.so I thought of posting this question. </p>  <p>Would there be any better way of achieving a worthwhile amount of compression of the result set ? I am looking at ease of compression and speed of decompression as the most important factor and best compression ratio as second preference. </p>  <p>Would the type/combination of streams used have an effect of the expected outcome ? </p>  <p>Are there any other custom / third party compression algorithms that offer far better performance improvements? </p>  <p><strong><em>Update - Some possible leads related issue</em></strong></p>  <ul> <li><p>Compression of searilized objects in Java is usually not very good. A Java object has a lot of additional information not needed. If you have millions of objects you have this overhead millions of times.</p></li> <li><p>If possible write the objects to a database, datastore or file and use caching to keep frequently used objects in memory.</p></li> <li><p>If size is important, you might like to have a simple serialization of your own. Using ObjectOutputStream is probably not the answer. This is because ObjectOutputStream has a significant overhead making small objects much larger.The stream format includes a lot of type-related metadata. If you are serializing small objects, the mandatory metadata will make it hard for the compression algorithm to "break even", even if you implement custom serialization methods.</p></li> <li><p>Using DataOutputStream with minimal (or no) added type information will give a better result. For better compression, you may need to look at the properties of the data that you are compressing.Mixed data is not generally that compressible using a general purpose compression algorithms.</p></li> <li><p>Use DeflatorOutputStream and InflatorInputStream as these are simpler/faster/smaller than the alternatives. The reason it is smaller is it just does the compression whereas the alternatives add file format extensions like CRC checks and headers.</p></li> <li><p>It may not be a good thing to compress all your data. For instance a serialized empty array may be several dozen of bytes long as the name of the underlying class is in the serialized data stream. Also most compression algorithm are designed to remove redundancy from large data blocks. On small to medium Java objects you'll probably have very little or no gain at all.</p></li> <li><p>Java ZIP also offers a alternative. Java supports ZipStream. All you need is to serialize your object into byte array and then zip it.</p></li> <li><p>Use ByteArrayOutputStream, DataStream, ZipOutputStream. But some argue that zip DEFLATE algorithm is quite old and the algorithm used in gzip, bzip2 or 7zip/lzma are probably more efficient. you will get MUCH better compression using bzip, or tar.gz. Apache Compress is the easiest way to work with those formats, if you're willing to accept the extra JAR dependencies.</p></li> </ul>