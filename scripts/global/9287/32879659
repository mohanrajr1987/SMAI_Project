<p>I have coded a web crawler. But when crawling it downloads too many GBs of data.</p>  <p>I want to read only the text (avoiding images ...etc).</p>  <p>I use <strong>Boilerpipe</strong> to extract the content from html</p>  <p>Here is how I find the final redirected url</p>  <pre><code>public String getFinalRedirectedUrl(String url) throws IOException{     HttpURLConnection connection;     String finalUrl = url;     int redirectCount = 0;     do {         connection = (HttpURLConnection) new URL(finalUrl)                 .openConnection();         connection.setConnectTimeout(Config.HTTP_CONNECTION_TIMEOUT_TIME);         connection.setReadTimeout(Config.HTTP_READ_TIMEOUT_TIME);         connection.setInstanceFollowRedirects(false);         connection.setUseCaches(false);         connection.setRequestMethod("GET");         connection.connect();         int responseCode = connection.getResponseCode();         if (responseCode &gt;= 300 &amp;&amp; responseCode &lt; 400) {             String redirectedUrl = connection.getHeaderField("Location");             if (null == redirectedUrl)                 break;             finalUrl = redirectedUrl;             redirectCount++;             if(redirectCount &gt; Config.MAX_REDIRECT_COUNT){                 throw new java.net.ProtocolException("Server redirected too many  times ("+Config.MAX_REDIRECT_COUNT+")");             }         } else{             break;         }     } while (connection.getResponseCode() != HttpURLConnection.HTTP_OK);     connection.disconnect();      return finalUrl; } </code></pre>  <p>This is how I fetch the url</p>  <pre><code>private HTMLDocument fetch(URL url) throws IOException{     final HttpURLConnection httpcon = (HttpURLConnection) url.openConnection();     httpcon.setFollowRedirects(true);     httpcon.setConnectTimeout(Config.HTTP_CONNECTION_TIMEOUT_TIME);     httpcon.setReadTimeout(Config.HTTP_READ_TIMEOUT_TIME);     httpcon.addRequestProperty("User-Agent", "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:10.0.2) Gecko/20100101 Firefox/10.0.2");     final String ct = httpcon.getContentType();      Charset cs = Charset.forName("Cp1252");     if (ct != null) {         if(!ct.contains("text/html")){             System.err.println("Content type is:"+ct);             return new HTMLDocument("");         }          Matcher m = PAT_CHARSET.matcher(ct);         if(m.find()) {                 final String charset = m.group(1);                 try {                         cs = Charset.forName(charset);                 } catch (UnsupportedCharsetException | IllegalCharsetNameException e) {                         // keep default                 }         }     }      InputStream in = httpcon.getInputStream();      final String encoding = httpcon.getContentEncoding();     if(encoding != null) {         if("gzip".equalsIgnoreCase(encoding)) {                 in = new GZIPInputStream(in);         } else {                 System.err.println("WARN: unsupported Content-Encoding: "+encoding);         }     }      ByteArrayOutputStream bos = new ByteArrayOutputStream();     byte[] buf = new byte[4096];     int r;     while ((r = in.read(buf)) != -1) {         bos.write(buf, 0, r);     }     in.close();      final byte[] data = bos.toByteArray();      return new HTMLDocument(data, cs); } </code></pre>  <p>And to get the body using <strong>Boilerpipe</strong></p>  <pre><code>HTMLDocument htmlDoc = fetch(new URL(url)); String body = ArticleExtractor.INSTANCE.getText(htmlDoc.toInputSource()); </code></pre>  <p><strong>How to reduce the amount of data downloaded?</strong></p>