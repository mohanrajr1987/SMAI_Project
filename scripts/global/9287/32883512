<p>I recently discovered the rvest package in R and decided to try out some web scraping.</p>  <p>I wrote a small web crawler in a function so I could pipe it down to clean it up etc.</p>  <p>With a small url list (e.g. 1-100) the function works fine, however when a larger list is used the function hangs at some point. It seems like one of the commands is waiting for a response but does not seems to get one and does not result in an error.</p>  <pre><code>urlscrape&lt;-function(url_list) {  library(rvest) library(dplyr) assets&lt;-NA price&lt;-NA description&lt;-NA city&lt;-NA length(url_list)-&gt;n pb &lt;- txtProgressBar(min = 0, max = n, style = 3)   for (i in 1:n) { #scraping for price# try( {read_html(url_list[i]) %&gt;% html_node(".price span") %&gt;% html_text()-&gt;price[i]}, silent=TRUE)  #scraping for city# try( {read_html(url_list[i]) %&gt;% html_node(".city") %&gt;% html_text()-&gt;city[i]}, silent=TRUE)  #scraping for description# try( {read_html(url_list[i]) %&gt;% html_nodes("h1") %&gt;% html_text() %&gt;% paste(collapse=" ") -&gt;description[i]}, silent=TRUE)  #scraping for assets# try( {read_html(url_list[i]) %&gt;% html_nodes(".assets&gt;li") %&gt;% html_text() %&gt;% paste(collapse=" ") -&gt;assets[i]}, silent=TRUE)  Sys.sleep(2) setTxtProgressBar(pb, i) }   Sys.time()-&gt;time print("") paste("Finished at",time) %&gt;% print() print("") return(as.data.frame(cbind(price,city,description,assets)) ) } </code></pre>  <p>(1) Without knowing the exact problem I looked for a timeout option in the rvest package with no avail. I then tried to use the timeout option in the httr package (with still console hanging as a result). For ".price" it would become:</p>  <pre><code>content(GET(url_list[i], timeout=(10)), timeout=(10), as="text") %&gt;% read_html() %&gt;% html_node(".price span") %&gt;% html_text()-&gt;price[i]}, silent=TRUE) </code></pre>  <p>I thought of other solutions and tried to implement them, but it did not work.</p>  <p>(2) Timelimit with setTimeLimit:</p>  <pre><code>length(url_list)-&gt;n pb &lt;- txtProgressBar(min = 0, max = n, style = 3) setTimeLimit(elapsed=20) </code></pre>  <p>(3) Test for url succes, with c increasing after the 4th scrape:</p>  <pre><code>for (i in 1:n) {         while(url_success(url_list[i])==TRUE &amp; c==i) { </code></pre>  <p>None of it worked and thus the function still hangs when the url list is big. Question: why would the console hang and how could it be solved? Thanks for reading.</p>