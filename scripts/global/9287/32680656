<p>I'm new to python. When I tried to run a crawler that just fetches the links in a page, I got this error.I have python 2.7 installed and working on osx. What my crawler does is, it goes to page and tries to find all the links present in that page and stores all those links in a list. Next we try to crawl all the new links, and continue to repeat the same till there are no links to crawl.</p>  <pre><code> File "crawler.py", line 44, in &lt;module&gt;  print crawl_web("https://en.wikipedia.org/wiki/Devil_May_Cry_4")  File "crawler.py", line 7, in crawl_web    union(tocrawl,get_all_links(get_page(page)))  File "crawler.py", line 19, in get_page    response = urllib.urlopen(a)  File" /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.py", line 87, in urlopen return opener.open(url)  File "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.py", line 213, in open return getattr(self, name)(url) File "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.py", line 469, in open_file return self.open_local_file(url) File "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib.py", line 483, in open_local_file raise IOError(e.errno, e.strerror, e.filename) IOError: [Errno 2] No such file or directory:'/w/load.phpdebug=false&amp;amp;lang=en&amp;amp; modules=ext.cite.styles|ext.gadget.DRN-wizard,ReferenceTooltips,charinsert,featured- articleslinks,refToolbar,switcher,teahouse|ext.wikimediaBadges&amp;amp;only=styles&amp;amp; skin=vector' </code></pre>  <p>Here's the code that I ran</p>  <pre><code>def crawl_web(page):   tocrawl = [page]   crawled = []   while tocrawl:      page = tocrawl.pop()      if page not in crawled:          union(tocrawl,get_all_links(get_page(page)))          crawled.append(page)      return crawled  def union(a,b):  for e in b:     if e not in a:         a.append(e)  import urllib def get_page(a):  response = urllib.urlopen(a)  data = response.read() return data  def get_all_links(page):  links = []  while True:     url,endpos = get_next_target(page)     if url:         links.append(url)         page = page[endpos:]     else:         break return links  def get_next_target(page):   start_link = page.find('href=')   if start_link == -1:     return None,0   start_quote = page.find('"',start_link)   end_quote = page.find('"',start_quote+1)   url = page[start_quote +1:end_quote]   return url,end_quote   print crawl_web("https://en.wikipedia.org/wiki/Devil_May_Cry_4")' </code></pre>