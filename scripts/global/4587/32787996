<p>I have compressed file and it contains 8 xml files of size 5-10kb. I took this data for testing purpose. I wrote one map only program to uncompress the compressed file. I <code>wrote program in MR2 and using Hadoop 2.7.1 in psuedo distributed mode</code>. I start the cluster using <code>sbin/start-dfs.sh</code> command. I am able to see the decompressed output in the file system within few seconds but the processing continues for next 5-6 minutes. I don't know why?</p>  <p><a href="http://i.stack.imgur.com/JpRaM.png" rel="nofollow"><img src="http://i.stack.imgur.com/JpRaM.png" alt="enter image description here"></a></p>  <p>MR program uncompressed the files till this stage and I can view / download those files.</p>  <p><a href="http://i.stack.imgur.com/I0QCA.png" rel="nofollow"><img src="http://i.stack.imgur.com/I0QCA.png" alt="enter image description here"></a> </p>  <p>Not able to understand what processing my mapreduce program is doing here. I <code>am using MR2 API in my code and why it is using MR1 API(mapred) here?</code> Situation become worse when I have 128mb of zipped files and it uncompressed in 5-10 mins and rest of the time it is busy in doing some other tasks.</p>  <p>The performance I am getting in unacceptable and need to understand what processing hadoop does in 2nd screen shot.</p>  <p>Please help me to understand whether it is installation issue, my program issue or any other issue?</p>