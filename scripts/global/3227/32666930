<p>After some time looking at the mongodb documentation and the pymongo API, I am still no clearer on what route I take as the way forward (more confused now that when I started) . My problem concerns locks ... not so much that I have tested and found there to be major concurrency problems, but that I don't want to run into them after the fact.</p>  <p>I have a tkinter script with several functions, all of them need access to the same document collection, and most of them access the same single document within that collection.</p>  <pre><code>client = MongoClient()  def 1 ():     glob_client  = client['ALPHA']['A-Z']     #do work:     """Also call subprocesses that use the same database document (glob_client) in another script.     There can be 3 -10 instances of this subprocess running, listening to various http streams in a while loop,      collecting data that can come in at 100's of times per second."""  def2 ():     glob_client  = client['ALPHA']['A-Z'] ...  def32 ():     glob_client  = client['ALPHA']['A-Z'] </code></pre>  <p>And the called subprocess(in separate scripts), multiple instances possible:</p>  <pre><code>client = MongoClient() glob_client  = client['ALPHA']['A-Z']  while True:     #do work with glob_client; updates, push, pull, reads,    </code></pre>  <p>So, would it be enough in this case to just use client.close() in every function?</p>  <pre><code>def 1 ():     glob_client  = client['ALPHA']['A-Z']     #do work     client.close() </code></pre>  <p>Similarly in the while loops:</p>  <pre><code>while True:     #do work with glob_client; updates, push, pull, reads,      Client.close() </code></pre>  <p>Would that suffice, or should I be looking to shard in this case? Or should I just go back to SQL!</p>  <p>Mongodb 3.0.6 32-bit, pymongo 3.03, python 2.7.</p>