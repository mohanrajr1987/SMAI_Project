<p>I have a Python program that uses Pytables, and I realized with profiling that a lot of time is spent in a function that queries a table in this simple manner: </p>  <pre><code>def get_element(table, somevar):     rows = table.where("somecolumn == somevar")     row = next(rows, None)     if row:         return elem_from_row(row) </code></pre>  <p>So I decided to try to sort the table to reduce the query time. This indeed improved the query time (spent in <code>where</code>), but it increased the time spent in the <code>next()</code> built-in function by several orders of magnitude! What could be the reason?</p>  <p>To help me understand the problem and make sure this was not related to something else in my program, I made this minimum working example reproducing the problem:</p>  <pre><code>#!/usr/bin/env python # -*- coding: utf-8 -*-  import tables import time import sys   def create_set(sort, withdata):     #Table description with or without data     tabledesc = {         'id': tables.UIntCol()     }     if withdata:         tabledesc['data'] = tables.Float32Col(2000)      #Create table with CSI'ed id     fp = tables.open_file('tmp.h5', mode='w')     table = fp.create_table('/', 'myset', tabledesc)     table.cols.id.create_csindex()      #Fill the table with sorted ids     row = table.row     for i in xrange(500):         row['id'] = i         row.append()      #Force a sort if asked for     if sort:         newtable = table.copy(newname='sortedset', sortby='id')         table.remove()         newtable.rename('myset')     fp.flush()     return fp   def get_element(table, i):     #By construction, i always exists in the table     rows = table.where('id == i')     row = next(rows, None)     if row:         return {'id': row['id']}     return None   sort = sys.argv[1] == 'sort' withdata = sys.argv[2] == 'withdata' fp = create_set(sort, withdata)  start_time = time.time() print("Querying the set...") table = fp.root.myset for i in xrange(500):     get_element(table, i) print("Done in %.3fs" % (time.time() - start_time)) fp.close() </code></pre>  <p>And here is some console output showing the figures:</p>  <blockquote> <pre><code>$ ./timedset.py nosort nodata Querying the set... Done in 0.718s $ ./timedset.py sort nodata Querying the set... Done in 0.003s $ ./timedset.py nosort withdata Querying the set... Done in 0.597s $ ./timedset.py sort withdata Querying the set... Done in 5.846s </code></pre> </blockquote>  <p>Some notes:</p>  <ul> <li>The rows are actually sorted in all cases, so it seems to be linked to the table structure created by <code>copy()</code> with the <code>sortby</code> parameter</li> <li>If instead of creating the file, I read it from disk, same results</li> <li>The issue occurs only when the data column is present, even though I never write to it nor read it. I noticed that the time difference increases when the size of the column (the number of floats) increases. The slowdown must be linked with internal data movements or I/O.</li> <li>If I don't use the <code>next</code> function, but instead use a <code>for row in rows</code> and trust that there is only one result, the slowdown still occurs.</li> </ul>  <p>Accessing an element from a table by some sort of id (sorted or not) sounds like a basic feature, I must be missing the typical way of doing it with pytables. What is it? And why such a terrible slowdown? Is it a bug that I should report?</p>