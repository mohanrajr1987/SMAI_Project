<p>I have a basic question about which optimization function I should use. I have:</p>  <ol> <li><p>A model of my system implemented as a python function. This function takes a one dimensional array and outputs a one dimensional array, and also takes a handful of parameters (usually less than 10).</p></li> <li><p>Noisy sample output from that function with unknown input parameters.</p></li> <li><p>Lower and upper bounds on each of the parameters.</p></li> </ol>  <p>What I want:</p>  <p>An optimization routine that allows me to throw all of the above in and get best-fit function parameters out.</p>  <p>I would like to treat the function as a black box, so no assumptions on it being continuous.</p>  <p>I had some luck with the <code>scipy.optimize.curve_fit</code> function, however it seemed very susceptible to deviations in the initial guess. <code>curve_fit</code> also didn't let me provide bounds on the input, which I think would greatly simplify the problem. Here is the code I used with curve_fit:</p>  <pre><code>import numpy as np from scipy import optimize  def model(x, c, d):     res = np.sqrt((d/2.0)**2 - (x-c)**2) + (d/2.0)     res[np.isnan(res)] = 0     return res  x = np.arange(-1000, 1000, 200) y = model(x, 0, 250) y_noise = y + np.random.rand(len(y)) * 20 - 10  popt, pcov = optimize.curve_fit(model, x, y_noise, (50, 200)) </code></pre>  <p>The above code returned (50, 200) as the optimized parameters, which is wrong. If I change the initial guess from (50, 200) to (49, 200) then the optimized parameters it returns are (1.84747802,  247.18634951), which is close enough to the truth of (0, 250)</p>  <p>Researching online seems to indicate that either RBF or least squares could help me. However I am having trouble posing my problem as something to be "minimized".</p>  <p>An example of calling my model above with the correct function would be greatly appreciated, as would general pointers to more reading that might help me.</p>  <p>Thanks in advance.</p>