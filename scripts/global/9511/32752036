<p>I have an MVC application that requires me to upload a data file to it. The need for the data file is to update records in our database.</p>  <p>The issue is that when I try to read the file to save to the database, I get an OutOfMemoryException. The size of the file I am uploading is 186MB. I am successful on a smaller file, roughly 120MB.</p>  <p>It throws the exception on the CopyTo line of code. However, I have tried using a BinaryReader and even saving the file to the sever and reading it back and neither way made a difference. Same exception gets thrown. My controller action is:</p>  <pre><code>public ActionResult UpdateAddresses(HttpPostedFileBase addressFile)     {         using (var addressStream = new MemoryStream())         {             addressFile.InputStream.CopyTo(addressStream);             var addressFileName = addressFile.FileName;             addressFile = null;              documentService.AddDocument(DateTime.Now, addressFile.FileName, FileTypes.ProducerAddressUpdate, addressStream.ToArray(), this.CurrentUser.AccountName);         }          return Index();     } </code></pre>  <p>I have also tried reading in the stream. The problem with that apporach is that I get an out of memory exception as soon as I declare the byte[]. Its as if the byte array is too large for .NET to handle. This would surprise me as a file of this size is not that large. At least not compared to gigabytes of data.</p>