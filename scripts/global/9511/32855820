<p>Trying to explore google dataflow sliding window feature, using following snippet, to do something like 2 seconds average and write out every 1 second.</p>  <pre><code>              SlidingWindows.of(Duration.standardSeconds(2)).every(Duration.standardSeconds(1))).discardingFiredPanes()); </code></pre>  <p>For local testing, it works with smaller size of data, like 1M rows, if increase the input data size to ~10M, got the out-of-memory stack, </p>  <p>wondering if there is some way we can tune or profile the pipeline?</p>  <p>Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded     at java.util.Arrays.copyOf(Arrays.java:3332)     at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137)     at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121)     at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:421)     at java.lang.StringBuilder.append(StringBuilder.java:136)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner$Evaluator.ensureElementEncodable(DirectPipelineRunner.java:872)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner$Evaluator.ensurePCollectionEncodable(DirectPipelineRunner.java:864)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner$Evaluator.setPCollectionValuesWithMetadata(DirectPipelineRunner.java:785)     at com.google.cloud.dataflow.sdk.transforms.ParDo.evaluateSingleHelper(ParDo.java:1032)     at com.google.cloud.dataflow.sdk.transforms.ParDo.access$100(ParDo.java:436)     at com.google.cloud.dataflow.sdk.transforms.ParDo$1.evaluate(ParDo.java:1007)     at com.google.cloud.dataflow.sdk.transforms.ParDo$1.evaluate(ParDo.java:1002)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner$Evaluator.visitTransform(DirectPipelineRunner.java:702)     at com.google.cloud.dataflow.sdk.runners.TransformTreeNode.visit(TransformTreeNode.java:219)     at com.google.cloud.dataflow.sdk.runners.TransformTreeNode.visit(TransformTreeNode.java:215)     at com.google.cloud.dataflow.sdk.runners.TransformHierarchy.visit(TransformHierarchy.java:99)     at com.google.cloud.dataflow.sdk.Pipeline.traverseTopologically(Pipeline.java:252)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner$Evaluator.run(DirectPipelineRunner.java:658)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner.run(DirectPipelineRunner.java:370)     at com.google.cloud.dataflow.sdk.runners.DirectPipelineRunner.run(DirectPipelineRunner.java:87)     at com.google.cloud.dataflow.sdk.Pipeline.run(Pipeline.java:174)</p>