<p>I'm new to Pandas and am trying to merge a few subsets of data.  I'm giving a specific case where this happens, but the question is general:  How/why is it happening and how can I work around it?</p>  <p><strong>The data I load is around 85 Megs or so but I often watch my python session run up close to 10 gigs of memory usage then give a memory error.</strong></p>  <p>I have no idea why this happens, but it's killing me as I can't even get started looking at the data the way I want to.</p>  <p>Here's what I've done:</p>  <p><strong>Importing the Main data</strong></p>  <pre><code>import requests, zipfile, StringIO import numpy as np import pandas as pd    STAR2013url="http://www3.cde.ca.gov/starresearchfiles/2013/p3/ca2013_all_csv_v3.zip" STAR2013fileName = 'ca2013_all_csv_v3.txt'  r = requests.get(STAR2013url) z = zipfile.ZipFile(StringIO.StringIO(r.content))  STAR2013=pd.read_csv(z.open(STAR2013fileName)) </code></pre>  <p><strong>Importing some Cross Cross Referencing Tables</strong> </p>  <pre><code>STARentityList2013url = "http://www3.cde.ca.gov/starresearchfiles/2013/p3/ca2013entities_csv.zip" STARentityList2013fileName = "ca2013entities_csv.txt" r = requests.get(STARentityList2013url) z = zipfile.ZipFile(StringIO.StringIO(r.content)) STARentityList2013=pd.read_csv(z.open(STARentityList2013fileName))  STARlookUpTestID2013url = "http://www3.cde.ca.gov/starresearchfiles/2013/p3/tests.zip" STARlookUpTestID2013fileName = "Tests.txt" r = requests.get(STARlookUpTestID2013url) z = zipfile.ZipFile(StringIO.StringIO(r.content)) STARlookUpTestID2013=pd.read_csv(z.open(STARlookUpTestID2013fileName))  STARlookUpSubgroupID2013url = "http://www3.cde.ca.gov/starresearchfiles/2013/p3/subgroups.zip" STARlookUpSubgroupID2013fileName = "Subgroups.txt" r = requests.get(STARlookUpSubgroupID2013url) z = zipfile.ZipFile(StringIO.StringIO(r.content)) STARlookUpSubgroupID2013=pd.read_csv(z.open(STARlookUpSubgroupID2013fileName)) </code></pre>  <p><strong>Renaming a Column ID to Allow for Merge</strong></p>  <pre><code>STARlookUpSubgroupID2013 = STARlookUpSubgroupID2013.rename(columns={'001':'Subgroup ID'}) STARlookUpSubgroupID2013 </code></pre>  <p><strong>Successful Merge</strong></p>  <pre><code>merged = pd.merge(STAR2013,STARlookUpSubgroupID2013, on='Subgroup ID') </code></pre>  <p><strong><em>Try a second merge.  This is where the Memory Overflow Happens</em></strong></p>  <pre><code>merged=pd.merge(merged, STARentityList2013, on='School Code') </code></pre>  <p>I did all of this in ipython notebook, but don't think that changes anything.</p>