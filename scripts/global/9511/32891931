<p>I want to create a ZipOutputStream filled with PDF-As. I'm using iText (Version 5.5.7). For more than 1000 pdf entries I get an OutOfMemory-exception on doc.close() and can't find the leak.</p>  <pre><code>ByteArrayOutputStream baos = new ByteArrayOutputStream(); ZipOutputStream zos = new ZipOutputStream(new BufferedOutputStream(baos)); zos.setEncoding("Cp850"); for (MyObject o : objects) { try {     String pdfFilename = o.getName() + ".pdf";     zos.putNextEntry(new ZipEntry(pdfFilename));     pdfBuilder.buildPdfADocument(zos);     zos.closeEntry(); } ... </code></pre>  <p>PdfBuilder</p>  <pre><code>public void buildPdfADocument(org.apache.tools.zip.ZipOutputStream zos){    Document doc = new Document(PageSize.A4);    PdfAWriter writer = PdfAWriter.getInstance(doc, zos, PdfAConformanceLevel.PDF_A_1B);    writer.setCloseStream(false); // to not close my zos    writer.setViewerPreferences(PdfWriter.ALLOW_PRINTING | PdfWriter.PageLayoutSinglePage);    writer.createXmpMetadata();    doc.open();    // adding Element's to doc    // with flushContent() on PdfPTables    InputStream sRGBprofile = servletContext.getResourceAsStream("/WEB-INF/conf/AdobeRGB1998.icc");    ICC_Profile icc = ICC_Profile.getInstance(sRGBprofile);    writer.setOutputIntents("Custom", "", "http://www.color.org", "sRGB IEC61966-2.1", icc);    //try to close/flush everything possible    doc.close();    writer.setXmpMetadata(null);    writer.flush();    writer.close();    if(sRGBprofile != null){      sRGBprofile.close();    } } </code></pre>  <p>Any suggestions how can I fix it? Am I forgetting something? I've already tried to use java ZipOutputStream but it makes any difference.</p>  <hr>  <p>Thx for ur answers! I understand the issue with the ByteOutputStream, but I am not sure what's the best approach in my case. It's a web application and I need to pack the zip in a database blob somehow.</p>  <p>What I am doing now is creating the PDFs directly into the ZipOutputStream with iText and saving byte array of the corresponding ByteArrayOutputSteam to blob. Options that I see are:</p>  <p>Split my data in 500 object packages, save first 500 PDFs to the database and then open the zip and add the next 500 ones and so on... But I assume that this creates me the same situation as I have now, namely too big stream opened in the memory.</p>  <p>Try to save the PDFs on the server (not sure if there's enough space), create temporary zip file and then submit the bytes to the blob...</p>  <p>Any suggestions/ideas?</p>