<p>We're running Hive on Hadoop leveraging Google Cloud Storage using bdutil version 1.3.2.  One of the options that we installed is TEZ.  </p>  <blockquote>   <p>AMBARI_SERVICES='FALCON FLUME GANGLIA HBASE HDFS KAFKA KERBEROS MAPREDUCE2 NAGIOS OOZIE SLIDER SQOOP STORM TEZ YARN ZOOKEEPER KNOX HIVE PIG'</p> </blockquote>  <p>When running a query using the mapreduce query engine, everything runs as expected:</p>  <blockquote>   <p>set hive.execution.engine=mr;</p> </blockquote>  <p>But, if I change the execution engine to tez:</p>  <blockquote>   <p>set hive.execution.engine=tez;</p> </blockquote>  <p>I get a long stacktrace, but the error is:</p>  <blockquote>   <p>Status: Failed   Vertex failed, vertexName=Map 4, vertexId=vertex_1443128249582_0182_1_00, diagnostics=[Vertex vertex_1443128249582_0182_1_00 [Map 4] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: t1 initializer failed, vertex=vertex_1443128249582_0182_1_00 [Map 4], java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem not found</p> </blockquote>  <p>I'm assuming that means that the gcs connector jar isn't in the right path, so I've added a link to the jar to the below paths, but still get the same error:</p>  <blockquote>   <p>/usr/hdp/2.2.6.0-2800/hadoop/lib/gcs-connector-1.4.2-hadoop2.jar <BR>   /usr/hdp/2.2.6.0-2800/tez/lib/gcs-connector-1.4.2-hadoop2.jar <BR>   /usr/hdp/2.2.6.0-2800/tez/gcs-connector-1.4.2-hadoop2.jar <BR>   /usr/lib/hadoop/lib/gcs-connector-1.4.2-hadoop2.jar <BR></p> </blockquote>  <p>Any thoughts on what needs changed to enable tez?</p>  <p>Thanks for your help.</p>  <p>The full stack trace is:<BR> Status: Failed Vertex failed, vertexName=Map 4, vertexId=vertex_1443128249582_0182_1_00, diagnostics=[Vertex vertex_1443128249582_0182_1_00 [Map 4] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: t1 initializer failed, vertex=vertex_1443128249582_0182_1_00 [Map 4], java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem not found     at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2076)     at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2601)     at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2614)     at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)     at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2653)     at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2635)     at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)     at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)     at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:256)     at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)     at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)     at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:300)     at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:402)     at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:130)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:245)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:239)     at java.security.AccessController.doPrivileged(Native Method)     at javax.security.auth.Subject.doAs(Subject.java:415)     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:239)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:226)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.ClassNotFoundException: Class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem not found     at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1982)     at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2074)     ... 24 more ] Vertex failed, vertexName=Map 3, vertexId=vertex_1443128249582_0182_1_01, diagnostics=[Vertex vertex_1443128249582_0182_1_01 [Map 3] killed/failed due to:ROOT_INPUT_INIT_FAILURE, Vertex Input: t2 initializer failed, vertex=vertex_1443128249582_0182_1_01 [Map 3], java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem not found     at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2076)     at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2601)     at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2614)     at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)     at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2653)     at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2635)     at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)     at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)     at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:256)     at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)     at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)     at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:300)     at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:402)     at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:130)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:245)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable$1.run(RootInputInitializerManager.java:239)     at java.security.AccessController.doPrivileged(Native Method)     at javax.security.auth.Subject.doAs(Subject.java:415)     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:239)     at org.apache.tez.dag.app.dag.RootInputInitializerManager$InputInitializerCallable.call(RootInputInitializerManager.java:226)     at java.util.concurrent.FutureTask.run(FutureTask.java:262)     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)     at java.lang.Thread.run(Thread.java:745) Caused by: java.lang.ClassNotFoundException: Class com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem not found     at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1982)     at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2074)     ... 24 more ] Vertex killed, vertexName=Map 1, vertexId=vertex_1443128249582_0182_1_02, diagnostics=[Vertex received Kill in INITED state., Vertex vertex_1443128249582_0182_1_02 [Map 1] killed/failed due to:null] Vertex killed, vertexName=Reducer 2, vertexId=vertex_1443128249582_0182_1_03, diagnostics=[Vertex received Kill in INITED state., Vertex vertex_1443128249582_0182_1_03 [Reducer 2] killed/failed due to:null] DAG failed due to vertex failure. failedVertices:2 killedVertices:2 FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask</p>