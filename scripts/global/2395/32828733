<p>I have created external table with text files of having 200GB of data. in that there might be possibility of duplicate records, in that case i have to throw exception. </p>  <p>I guess using group by we can eliminate duplicates but in my case i have to abort the process when duplicate records exist.</p>  <p>Please let me know, How to handle this problem? Is it possible with python UDF or in Hive (version 0.13) itself we can resolve this? </p>  <p>Thanks in advance.</p>