<p>my problem is very simple, I have a file which contains plenty of tweet one per row not surrounded by quotes. After reading the file I created "dataset", to randomize it and to eliminate duplicates:</p>  <pre><code>dataset &lt;- read.table(file, header=FALSE, sep="\n", stringsAsFactors=F) unique_ds &lt;- unique.data.frame(dataset) random_ds &lt;- unique_ds[sample(nrow(unique_ds)),] write.table(data.frame(random_ds),file="tweets_final.txt", sep="\n", quote=F, col.names=F, row.names=F) </code></pre>  <p><em>random_ds</em> has <strong>2246</strong> rows. But when I open my file I've just created, I see <strong>more than 5000 rows</strong>.</p>  <p><strong>First question:</strong> I just can't understand <strong>where</strong> is the problem. Is it maybe in write.table or the code above?</p>  <p>[consider that in each tweet in the original file, I've removed newline and carriage return; Java code below]</p>  <pre><code>out = out.replaceAll("[\n\r]", " "); </code></pre>  <p><strong>Second question:</strong> suppose to add per each row a new variable (for examples a category for the tweet), when I will read it back in R, like a csv file is this format appropriate: <em>"my tweet",type</em> with the code below?</p>  <pre><code>ds &lt;- read.csv(file = "tweet_classified.txt", header = FALSE, sep = ",",stringsAsFactors = FALSE, quote = "\"") </code></pre>  <p>In particular how could I manage in Java/R the problem of quotes inside quotes?</p>  <p>thanks</p>  <p><strong>Important</strong> I've just consider the fact that obviously, twitter data contain # character, so I would ask another question: is it possibile that sobsitute hashtags with \n? or just considers it as comment, and throws away tha part following #</p>