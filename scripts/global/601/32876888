<p>I have a Python script that moves a file from a server to HDFS using the following command:</p>  <pre><code>from subprocess import Popen . . filename = "/home/user123/test.csv" put = Popen(["hadoop", "fs", "-put", filename, "/data/test"])   </code></pre>  <p>The script works perfectly when I run it on the server, but when I run it as a cron job it fails with the following message:</p>  <pre><code>OSError: [Errno2] no such file or directory . .   File "/opt/anaconda/lib/python2.7/subprocess.py", line 710, in __init__     errread, errwrite)   File "/opt/anaconda/lib/python2.7/subprocess.py, line 1335, in _execute_child      raise child_exception </code></pre>  <p>I tried replacing "hadoop" with "/usr/bin/hadoop" but I still get a "No such file or directory" error. I assume this is an environment variables issue but is there a way to get around it?</p>