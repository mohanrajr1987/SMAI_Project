<p>I have a template file used to make a lot of new files based on a parameter list. Since I am going to make 4000 files I tried us the multiprocessing module module.  The code is about like this:</p>  <pre><code>from multiprocessing import Pool  def make_file(x):     Read textfile     Use x to change it     Save it with a new name      if __name__ == '__main__':         paramters = about 4000 parameters         p = Pool(5)         p.map(make_file,parameters) </code></pre>  <p>But when I tried it, it hang after about 2000 files was made. Is it stupid to read from the same file with multiple processes?</p>