<p>I have converted Fortran 95 code using f2py into a Python DLL/.so.  I use Python to execute the Fortran computations, returning large numpy arrays.  I run the Python scripts in a ProcessPoolExecutor (pool).  Everything works fine as long as the number of process &lt;= max number of worker processes: <code>Pool(max_workers)</code>.  </p>  <p>When I try to set the <code>max_workers</code> to a value &lt; the total number of processes I receive the follow (memory leak?) errors (note: two version of Python 2.7):</p>  <p><code>*** glibc detected *** python: free(): invalid pointer</code>  -- Python 2.7.6</p>  <p><code>*** glibc detected *** python: double free or corruption (!prev) ***</code>  -- Python 2.7.10</p>  <p>Basically, I am setting the the <code>max_workers</code> value based on the number of CPUs as reported by Python's <code>multiprocessing.cpu_count()</code>.  This is being run on a RHEL 5 server with 6 CPUs.  The work is divided across 16 processes.  It is in these conditions that I am thrown the above error.</p>  <p>If I run <code>max_processes = 16</code>, I do not generate the error (<code>max_processes</code> == total number of processes).</p>  <pre><code>    # In a class     self.no_of_processes = multiprocessing.cpu_count()     for x in range(self.no_of_processes):         pool.submit(             callable, arg1, arg2         ).add_done_callback(             partial(callback, arg1)         )  ----------------- # Outside of class def callable(arg1, arg2):     f2py_callable.run(arg1, arg2)  # This is in a separate module  def callback(arg1, future):     print "arg1 = ", arg1     print future.result()   ---------------------- # f2py_callable module def run(arg1, arg2):     import f2py_dll     out = f2py_dll.run_fortran(arg1, arg2)     # `out` is a Numpy multiarray and is sent using `requests` to a Mongo/Motor server after being pickled </code></pre>  <p>Any suggestions on this issue?  It seems that the Numpy array that holds the return array from Fortran is trying to be reused by the next Python process when the former process finishes??</p>  <p>Note: the Numpy array is pickled and sent off to another server in the subprocess before it is finished and before the next process would start in the process Pool; therefore, everything is embarrassingly parallel.</p>  <p>Numpy 1.8, Python 2.7.6 &amp; Python 2.7.10 (two slightly different errors), RHEL 5</p>