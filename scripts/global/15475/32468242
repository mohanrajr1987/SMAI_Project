<p>Is there any way to check the progress or current number of iterations of a <code>multiprocessing.Pool()</code> from the python stdlib? I know that it accepts a generator so I don't necessarily need it to tell me what total percent it is at, but it would be great to have an idea of progress / the number of iterations, or possibly even have a callback to emit output every x iterations.</p>  <p>I'm using this as a CLI tool, and would like to give users some idea of how long it will take before all the iterations finish, or even just provide some feedback for how quickly progress is being made (this process is a region-of-interest extractor for image values and depends heavily on disk IO, so it can be relatively quick or drag on forever depending on current load, and it would be nice for users to know which).</p>  <p>I'm imagining something like this:</p>  <pre><code>def itercallback(i):     if not i % 10:         print "Done %d... " % i  p = multiprocessing.pool() l = range(1000) data = p.map(lambda x: return x, l, itercallback) </code></pre>  <p>Should print...</p>  <pre><code>Done 10... Done 20... ... Done 990... </code></pre>  <p>I probably wouldn't actually just print, but would work this into a progress bar given the known total of iterations, but you get the idea.</p>  <p>What's the easiest way to implement something like this? There's nothing that I can see in the <a href="https://docs.python.org/dev/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow">multiprocessing</a> docs for counts or callbacks. I don't need any fancy pipes / queues / state-sharing since this is embarrassingly parallel, and I'd rather not re-write <code>Pool</code>, but would be open to using other parts of the <code>multiprocessing</code> lib. Any ideas on a feasible way to implement this that doesn't complicate the code much more than a normal pool?</p>