<p>I'd like to create a set of processes with the following structure:</p>  <ul> <li><code>main</code>, which dequeues requests from an external source. <code>main</code> generates a variable number of worker processes.</li> <li><code>worker</code> which does some preliminary processing on job requests, then sends data to <code>gpuProc</code>. </li> <li><code>gpuProc</code>, which accepts job requests from <code>worker</code> processes. When it has received enough requests, it sends the batch to a process that runs on the GPU. After getting the results back, it has to then send back the completed batch of requests back to the <code>worker</code> processes such that <em>the worker that requested it receives it back</em> </li> </ul>  <p>One could envision doing this with a number of queues. Since the number of <code>worker</code> processes is variable, it would be ideal if <code>gpuProc</code> had a single input queue into which <code>worker</code>s put their job request and their specific return queue as a tuple. However, this isn't possible--you can only share vanilla queues in python via inheritance, and <code>manager.Queues()</code> fail with:</p>  <pre><code>RemoteError:  --------------------------------------------------------------------------- Unserializable message: ('#RETURN', ('Worker 1 asked proc to do some work.', &lt;Queue.Queue instance at 0x7fa0ba14d908&gt;)) --------------------------------------------------------------------------- </code></pre>  <p>Is there a pythonic way to do this without invoking some external library?</p>