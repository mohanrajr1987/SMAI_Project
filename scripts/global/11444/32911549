<p>I am trying to wordcount program using the MapReduce Hadoop technology. What I need to do is develop an Indexed Word Count application that will count the number of occurences of each word in each file in a given input file set. This file set is present in the Amazon S3 bucket. It will also count the total occurences of each word. I have attached the code that counts the occurences of the words in the given file set. After this I need to print that which word is occuring in which file with the number of occurrences of the word in that particular file.</p>  <p>I know its a bit complex but any would be appreciated.</p>  <p>Map.java</p>  <pre><code>import java.io.IOException; import java.util.*;  import org.apache.hadoop.io.*; import org.apache.hadoop.mapreduce.*; import org.apache.hadoop.mapreduce.lib.input.FileSplit;  public class Map extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {     private final static IntWritable one = new IntWritable(1);     private Text word = new Text();     private String pattern= "^[a-z][a-z0-9]*$";      public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {         String line = value.toString();         StringTokenizer tokenizer = new StringTokenizer(line);         InputSplit inputSplit = context.getInputSplit();         String fileName = ((FileSplit) inputSplit).getPath().getName();         while (tokenizer.hasMoreTokens()) {             word.set(tokenizer.nextToken());             String stringWord = word.toString().toLowerCase();             if (stringWord.matches(pattern)){                 context.write(new Text(stringWord), one);             }          }     } } </code></pre>  <p>Reduce.java</p>  <pre><code>import java.io.IOException;  import org.apache.hadoop.io.*; import org.apache.hadoop.mapreduce.*;  public class Reduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {      public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)     throws IOException, InterruptedException {         int sum = 0;         for (IntWritable val : values) {             sum += val.get();         }         context.write(key, new IntWritable(sum));     } }    </code></pre>  <p>WordCount.java</p>  <pre><code>import org.apache.hadoop.fs.Path; import org.apache.hadoop.conf.*; import org.apache.hadoop.io.*; import org.apache.hadoop.mapreduce.*; import org.apache.hadoop.mapreduce.lib.input.FileInputFormat; import org.apache.hadoop.mapreduce.lib.input.TextInputFormat; import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat; import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;  public class WordCount {     public static void main(String[] args) throws Exception {         Configuration conf = new Configuration();          Job job = new Job(conf, "WordCount");         job.setJarByClass(WordCount.class);         job.setOutputKeyClass(Text.class);         job.setOutputValueClass(IntWritable.class);          job.setNumReduceTasks(3);          job.setMapperClass(Map.class);         job.setReducerClass(Reduce.class);          job.setInputFormatClass(TextInputFormat.class);         job.setOutputFormatClass(TextOutputFormat.class);          FileInputFormat.addInputPath(job, new Path(args[0]));         FileOutputFormat.setOutputPath(job, new Path(args[1]));          job.waitForCompletion(true);     } } </code></pre>