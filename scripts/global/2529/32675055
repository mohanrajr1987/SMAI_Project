<p>Usually, <code>pygame</code> shows its output in a specially created window. Instead of creating this window, then saving images in sequence from it, before finally feeding these images to a tool like <code>ffmpeg</code>, I'd like to pipe <code>pygame</code>'s output directly <code>ffmpeg</code>.</p>  <p>Does what I want make sense?</p>  <p>If yes, how can I redirect <code>pygame</code>'s output to console? From the documentation, I am aware of methods like <code>pygame.Surface.get_view</code> or <code>pygame.Surface.get_buffer</code>, but I don't know what the difference is between them, and whether they are quite what I need. </p>  <p>In this <a href="http://zulko.github.io/blog/2013/09/27/read-and-write-video-frames-in-python-using-ffmpeg/" rel="nofollow">tutorial</a>, a raw <code>numpy</code>-array based RGB representation of images is fed to <code>ffmpeg</code>. I figure I could do a similar thing, except instead I'd feed in some sort of RGB representation obtained from <code>pygame</code>. </p>  <p>I know that on Linux, <a href="https://learn.adafruit.com/pi-video-output-using-pygame/pointing-pygame-to-the-framebuffer" rel="nofollow">it's possible to output <code>pygame</code> stuff to a framebuffer</a> for display in the console? Not sure if it is related. In any case, the effect is achieved by changing pygame drivers.</p>  <p>So, I have some dots, but need to connect them.</p>