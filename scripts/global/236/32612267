<p>So I'm working on an embedded project that needs to compute floating point numbers.  Obviously there's various ways to estimate the output and reduce compute cycles.  My question is, how expensive is a floating point compare vs an integer compare (relatively speaking, not exact cycles)?  One of the operation can probably be optimized this way, but I am wondering if it is worth the effort.  The chip is a cortex M0 (no floating point hardware).  All floating point is done through software.</p>