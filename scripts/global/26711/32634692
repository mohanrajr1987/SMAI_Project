<p>I'm experimenting with image processing algorithms on iOS. I've got an asset catalog with images <code>test_frame1</code> ... <code>test_frame100</code> (and the like) on which I do some processing.</p>  <p>Among other things I need to display the images sequentially as if they were frames of a video.</p>  <p>The first thing that came to my mind is sequentially change the image of a <code>UIImage</code> after some milliseconds delay. I'm doing this asynchronously. Here's the code:</p>  <pre><code>    let imageShowQueue = dispatch_queue_create("com.grigoryptashko.ImageShowQueue",         DISPATCH_QUEUE_SERIAL)     let frameShowDelay = Int64(0.2 * Double(NSEC_PER_SEC)) // show images with 200 ms delay, but it doesn't actually work this way     dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH, 0)) {         var dTime = dispatch_time(DISPATCH_TIME_NOW, frameShowDelay)         for i in 1...1000 {             dispatch_after(dTime, self.imageShowQueue) {                 dispatch_async(dispatch_get_main_queue()) {                     NSLog("test_frame\((i % 100) + 1)")                     self.imgView.image = UIImage(named: "test_frame\((i % 100) + 1)")                     self.imgView.setNeedsDisplay()                 }             }              dTime = dispatch_time(dTime, frameShowDelay)         }     } </code></pre>  <p>It actually works but the FPS quickly becomes too low, like 1 FPS or even slower. Is there any other way to achieve this?</p>  <p>Maybe, there is some way that I don't know about. For instance, recently I've learned about <code>Accelerate</code> framework and <code>Apple Metal</code>. Ant other ideas?</p>