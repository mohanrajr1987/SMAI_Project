<p>I want to extract a bunch of urls from a db <em>(the db contains a large set of urls)</em>, when a user searches for a particular keyword, for example "seattle dentist". I understand that the basic approach is to look for the page title, meta description, keywords and body text.</p>  <p>How can I do this with more accuracy that returns relevant result?</p>  <p>For example, I have two websites in question:</p>  <ol> <li><code>seattledentist.com</code> (which is a dentist website and has the title "seattle dentist")</li> <li><code>abcxyz.com/dentist-seattle</code>  (a wordpress blog page that has the word "seattle dentist" in its title)</li> </ol>  <p>For me, the first website is relevant and I want to show this site to a user when he searches for "seattle dentist". The second website is just a blog post that describes the dentistry profession in seattle and is not relevant for the user.</p>  <p>So my question is, what would be a better strategy(algorithm) for filtering out this type of non-relevant urls from a whole bunch of urls? </p>