<p>I have to scrape this website <a href="https://ssweb.seap.minhap.es/portalEELL/consulta_alcaldes" rel="nofollow">https://ssweb.seap.minhap.es/portalEELL/consulta_alcaldes</a>. </p>  <p>What I need to do is to get all names from all provinces and municipalities in one place. So for example in the first dropdown I select Alacant/Alicante and in the second I pick Adsubia. A list of names appears (city mayor and councillors) and I would like all this information. And the same for all municipalities in this province. After that I would change the province and go on with all the municipalities.</p>  <p>Does anyone have any ideas how to start ?</p>  <p>EDITED</p>  <p>Ok, I should have been more precise. Sorry. And as you probably figured out already I am a beginner in Python. I am learning BeautifulSoup but right now I am only able to scrape very simple websites. </p>  <p>My problem with this one is that I can't see the 'variable' element - something I could change to get to the data for each municipality. After inspecting it with Chrome I found <a href="https://ssweb.seap.minhap.es/portalEELL/consulta_alcaldes/getEntidades/provincia/0/" rel="nofollow">https://ssweb.seap.minhap.es/portalEELL/consulta_alcaldes/getEntidades/provincia/0/</a> . So by modifying the last number I could go to all provinces and then go through each drop down to get the names of municipalities. However they are not links so they don't take me to the results page. </p>  <p>I realize it's a basic question for you. What I need is a hint how to start.</p>  <p>Another thing is that I receive SSL error when trying to access this website with requests.get() function. Does it mean I can't extract data from this website? </p>  <pre><code>r =requests.get('https://ssweb.seap.minhap.es/portalEELL/consulta_alcaldes/') </code></pre>  <p>and the error I get:</p>  <pre><code>    --------------------------------------------------------------------------- SSLError                                  Traceback (most recent call last) C:\Anaconda3\lib\site-packages\requests\packages\urllib3\connectionpool.py in urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)     543                                                   timeout=timeout_obj, --&gt; 544                                                   body=body, headers=headers)     545  </code></pre>