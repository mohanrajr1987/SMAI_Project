<p>This script is generating a csv with the data from only one of the urls fed into it.  There are meant to be 98 sets of results, however the <code>for</code> loop isn't getting past the first url.</p>  <p>I've been working on this for 12hrs+ today, what am I missing in order get the correct results?</p>  <p>import requests     import re     from bs4 import BeautifulSoup     import csv</p>  <pre><code>#Read csv csvfile = open("gyms4.csv") csvfilelist = csvfile.read()  def get_page_data(urls):     for url in urls:         r = requests.get(url.strip())         soup = BeautifulSoup(r.text, 'html.parser')         yield soup    # N.B. use yield instead of return  print r.text  with open("gyms4.csv") as url_file:     for page in get_page_data(url_file):         name = page.find("span",{"class":"wlt_shortcode_TITLE"}).text         address = page.find("span",{"class":"wlt_shortcode_map_location"}).text         phoneNum = page.find("span",{"class":"wlt_shortcode_phoneNum"}).text         email = page.find("span",{"class":"wlt_shortcode_EMAIL"}).text          th = pages.find('b',text="Category")         td = th.findNext()         for link in td.findAll('a',href=True):             match = re.search(r'http://(\w+).(\w+).(\w+)', link.text)             if match:                 web_address = link.text  gyms = [name,address,phoneNum,email,web_address] gyms.append(gyms)  #Saving specific listing data to csv with open ("xgyms.csv", "w") as file:     writer = csv.writer(file)     for row in gyms:         writer.writerow([row]) </code></pre>