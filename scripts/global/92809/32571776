<p>I am new to iOS development, and looking to somehow present the volume iPhone microphone is receiving, and display it in bars.  I don't need to be accurate, i just want to display that there is some activity on the microphone, in a sense "the app is listening" but in the same time i want to show approximate whether the sound is loud or quite. </p>  <p>I have been looking through different questions here and on the web, but could not find anything specific. </p>  <p>I can tell you that at the moment the app has an oscilloscope representation of the microphone level, but i want to change that to be bars. </p>  <p>This is one function, that i think provides the current sample in order to display the oscilloscope </p>  <pre><code>-(void)setVisualizerDataWithData:(float *)audioSamples count:(int)count{ if (!audioSamples || !count) {     self.dataCount = 0;     return; }  //NSLog(@"%@", audioSamples);   // incoming is on audio thread, take care to protect data from async drawing on main UI thread if([audioDataLock tryLock]) {     int i, j;     for(i=0, j=0; i&lt;self.audioDataCapacity &amp;&amp; j&lt;count; i++, j+=kDownsampleResolution) {         self.audioData[i] = audioSamples[j];     }     self.dataCount = i;     [audioDataLock unlock]; } [self setNeedsDisplay]; </code></pre>  <p>}</p>  <p>And this parts draws the line in the oscilloscope:</p>  <pre><code>    - (void)drawRect:(CGRect)rect {     // Do as much of the heavy graphics context setup as possible before grabbing the data lock     CGContextRef c = UIGraphicsGetCurrentContext();     CGContextSetShouldAntialias(c, false);      CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();     CGFloat locations[] = { 0.0, 0.5, 1.0 };     NSArray *colors = @[(__bridge id)[UIColor colorWithWhite:0.15 alpha:0.3].CGColor,                         (__bridge id)[UIColor colorWithWhite:0.8 alpha:0.3].CGColor,                         (__bridge id)[UIColor colorWithWhite:0.15 alpha:0.3].CGColor                         ];     CGGradientRef gradient = CGGradientCreateWithColors(colorSpace, (__bridge CFArrayRef) colors, locations);     CGPoint startPoint = CGPointMake(CGRectGetMidX(rect), CGRectGetMinY(rect));     CGPoint endPoint = CGPointMake(CGRectGetMidX(rect), CGRectGetMaxY(rect));     CGContextSaveGState(c);     CGContextAddRect(c, rect);     CGContextClip(c);     CGContextDrawLinearGradient(c, gradient, startPoint, endPoint, 0);     CGContextRestoreGState(c);     CGGradientRelease(gradient);     CGColorSpaceRelease(colorSpace);      CGFloat zero = CGRectGetMidY(rect);     UIBezierPath *path = [UIBezierPath bezierPath];     UIColor *yellow = [UIColor yellowColor];     [yellow setStroke];      // if data is locked for incoming audio thread updates,     // just skip drawing the waveform and pick it up on next cycle     //     if([audioDataLock tryLock]) {         if (self.audioData &amp;&amp; self.dataCount) {             CGFloat ratio = CGRectGetWidth(rect) / self.dataCount;             ratio+=0.1;              [path moveToPoint:CGPointMake(0, zero)];              for (int i=0; i&lt;self.dataCount; i++) {                 int x = i * ratio;                 if (x &gt; CGRectGetMaxX(rect)) {                     break;                 }                 int y = zero + self.audioData[i] * kAudioBoost;                 int z = zero + self.audioData[i];                 NSLog(@"Volume %d,%d",x,y);                 [path addLineToPoint:CGPointMake(x, y)];             }              // release the lock before doing the expensive stroke             [audioDataLock unlock];             [path stroke];         } else {             [audioDataLock unlock];         }     } } </code></pre>  <p>Any help will be appreciated. </p>