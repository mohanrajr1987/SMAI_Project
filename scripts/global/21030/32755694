<p>Is there any advantage to <em>transforming</em> an image before computing SIFT features? For example, I am trying to match a "target" image of a banana: </p>  <p><a href="http://i.stack.imgur.com/Ae6Lq.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/Ae6Lq.jpg" alt="banana"></a></p>  <p>...to a "scene" image which also contains a banana, but in <em>some unknown orientation and perspective</em>.</p>  <p><strong>First approach</strong>: extract SIFT features from the target image, match them to SIFT features in the scene image and compute a homography.</p>  <p><strong>Second approach</strong>: transform the target image in various ways to <em>simulate changes of perspective</em>: </p>  <p><a href="http://i.stack.imgur.com/ALGJc.png" rel="nofollow"><img src="http://i.stack.imgur.com/ALGJc.png" alt="transformed bananas"></a></p>  <p>...before extracting SIFT features from each transform. Combine the extracted features and then match them to the scene and compute a homography. </p>  <p>Is there any advantage to approach 2, in terms of fidelity of feature matching? Thanks! </p>