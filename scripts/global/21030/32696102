<p>So I just did sebsastian thrun's course on AI. In there, he mentions how to build a particle filter for tracking a moving xy robot based on heading theta and forward movement.</p>  <p>The code is here: <a href="https://gist.github.com/soulslicer/b4765ee8e01958374d3b" rel="nofollow">https://gist.github.com/soulslicer/b4765ee8e01958374d3b</a></p>  <p>In his implementation, he does the following: </p>  <pre><code>1. Get Range from Sensor of all bearings after moving R=1, Theta=0.5 2. Move all the particles by R=1, Theta=0.5 3. Compute the weights of all particles ranges against the measured range from sensor 4. Resample and draw new particles </code></pre>  <hr>  <p>This works for a motion model great. How on earth would this work for computer vision tracking? For example, I want to track a yellow circular blob.  How would I "move" the particles? What might my cost functions be? Especially the moving part, I'm not sure how I'd do that step for computer vision tracking</p>  <hr>  <p>Here is how I think it might work, but I'm probably wrong:</p>  <pre><code>1. Get features from image, and compute the optical flow velocities of each feature 2. Place alot of particles in the scene with varying x,y,xvel,yvel 3. For the computation of weights, we can compare the each particle's velocity and position against all features     If we can threshold out the object based on color/shape, can match image features to shapes and put that in the cost function 4. Resample and draw new particles </code></pre>