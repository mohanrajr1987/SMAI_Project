<p>In the famous Google Inceptionism article, <a href="http://googleresearch.blogspot.jp/2015/06/inceptionism-going-deeper-into-neural.html" rel="nofollow">http://googleresearch.blogspot.jp/2015/06/inceptionism-going-deeper-into-neural.html</a> they show images obtained for each class, such as banana or ant. I want to do the same for other datasets.</p>  <p>The article does describe how it was obtained, but I feel that the explanation is insufficient.</p>  <p>There's a related code <a href="https://github.com/google/deepdream/blob/master/dream.ipynb" rel="nofollow">https://github.com/google/deepdream/blob/master/dream.ipynb</a></p>  <p>but what it does is to produce a random dreamy image, rather than specifying a class and learn what it looks like in the network, as shown in the article above.</p>  <p>Could anyone give a more concrete overview, or code/tutorial on how to generate images for specific class? (preferably assuming caffe framework)</p>