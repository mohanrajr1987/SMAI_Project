<p>Spark core supports both raw storage and serialized RDD caching. The good article <a href="http://sujee.net/2015/01/22/understanding-spark-caching" rel="nofollow">explains</a> this. If you use <strong><em>persist()</em></strong> - you may specify any of <a href="https://trongkhoanguyenblog.wordpress.com/2014/12/14/understand-the-storage-module-in-spark-core" rel="nofollow">levels</a> of caching, but if you're use <strong><em>cache()</em></strong> you may only use <em>MEMORY_ONLY</em> by default without serialization according this <a href="http://stackoverflow.com/questions/26870537/spark-what-is-the-difference-between-cache-and-persist">question</a>. Anyone know how to use MEMORY_ONLY_SER caching in SparkSQL? - “Cache table my_table;” going to cache with MEMORY_ONLY option, not with MEMORY_ONLY_SER, even if I have spark.storage.StorageLevel=MEMORY_ONLY_SER in spark environment by default.  My target is using serialized table caching from SparkSQL. Any ideas?</p>