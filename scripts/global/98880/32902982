<p>Suppose we have DataFrame <code>df</code> consisting of the following columns:</p>  <blockquote>   <p>Name, Surname, Size, Width, Length, Weigh</p> </blockquote>  <p>Now we want to perform a couple of operations, for example we want to create a couple of DataFrames containing data about Size and Width.</p>  <pre><code>val df1 = df.groupBy("surname").agg( sum("size") ) val df2 = df.groupBy("surname").agg( sum("width") ) </code></pre>  <p>as you can notice, other columns, like Length are not used anywhere. Is Spark smart enough to drop the redundant columns before the shuffling phase or are they carried around? Wil running:</p>  <pre><code>val dfBasic = df.select("surname", "size", "width") </code></pre>  <p>before grouping somehow affect the performance?</p>