<p>I use iPhone camera to capture images in my iOS APP. AVCaptureVideoDataOutputSampleBufferDelegate is used to get images from iPhone camera. A part of the program is shown below.</p>  <pre><code>AVCaptureDevice *videoDevice = [AVCamViewController deviceWithMediaType:AVMediaTypeVideo preferringPosition:AVCaptureDevicePositionBack];    AVCaptureDeviceInput *videoDeviceInput = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:&amp;error];    if (error) { NSLog(@"%@", error); }    if ([session canAddInput:videoDeviceInput])    {      [session addInput:videoDeviceInput]; [self setVideoDeviceInput:videoDeviceInput];      dispatch_async(dispatch_get_main_queue(),    ^{       [[(AVCaptureVideoPreviewLayer *)[[self previewView] layer] connection] setVideoOrientation:(AVCaptureVideoOrientation)[self interfaceOrientation]]; });    }   </code></pre>  <p>The quality of the image taken by AVCaptureVideoDataOutputSampleBufferDelegate and that of the image taken iPhone's camera app are much different. What are the parameters to adjust at  AVCaptureVideoDataOutputSampleBufferDelegate  to have the same or closer quality as camera app? The two images are attached. The second image is taken by iPhone camera's app. Thanks <a href="http://i.stack.imgur.com/3W9hM.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/3W9hM.jpg" alt="enter image description here"></a></p>  <p>EDIT: I can pinpoint where is the problem. I print two images before and after UIImage to cvMat conversion. In UIImage format, the image quality is quite good. After conversion, the quality becomes bad, the color is changed etc.. I attached two images before and after. The first one is before. <a href="http://i.stack.imgur.com/3OCc8.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/3OCc8.jpg" alt="enter image description here"></a> <a href="http://i.stack.imgur.com/mm2yl.jpg" rel="nofollow"><img src="http://i.stack.imgur.com/mm2yl.jpg" alt="enter image description here"></a> I used the following code to convert.</p>  <pre><code>- (cv::Mat)cvMatFromUIImage:(UIImage *)image {     CGColorSpaceRef colorSpace = CGImageGetColorSpace(image.CGImage);     CGFloat cols = image.size.width;     CGFloat rows = image.size.height;      cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels (color channels + alpha)      CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to  data                                                     cols,                       // Width of bitmap                                                     rows,                       // Height of bitmap                                                     8,                          // Bits per component                                                     cvMat.step[0],              // Bytes per row                                                     colorSpace,                 // Colorspace                                                     kCGImageAlphaNoneSkipLast |                                                     kCGBitmapByteOrderDefault); // Bitmap info flags      CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), image.CGImage);     CGContextRelease(contextRef);      return cvMat; } </code></pre>  <p>Writing the image to jpg file shouldn't be a problem. But this is the code to save image</p>  <pre><code>- (void) saveImage:(std::string)name img:(Mat)gray{     //Print     NSArray *paths = NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES);     NSString *documentsDirectory = [paths objectAtIndex:0];     NSString *filePath = [documentsDirectory stringByAppendingPathComponent:[NSString stringWithFormat:@"%3s.jpg", name.c_str()]];     const char* cPath = [filePath cStringUsingEncoding:NSMacOSRomanStringEncoding];     const cv::String newPaths = (const cv::String)cPath;      //Save as Bitmap to Documents-Directory     cv::imwrite(newPaths, gray); } </code></pre>  <p>Conversion code from UIImage to cvMat is quite standard and why it has this problem?</p>