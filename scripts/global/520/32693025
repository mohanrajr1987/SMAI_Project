<p>i use streaming/python to run hadoop job,but it has some error,i change mapper to /bin/cat,but also have this error, somebody tell me why?!</p>  <p>here is informations: hadoop 2.6 python 2.7.9</p>  <p>my bash shell:</p>  <blockquote>   <p>HPHOME=/software/servers/hadoop-2.6.0-bin/hadoop-2.6.0/bin/   JAR_PACKEGE=/software/servers/hadoop-2.6.0-bin/hadoop-2.6.0/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar</p>      <p>MAP=/bin/cat   RED=/usr/bin/uniq   IN_PATH=/ds/bl/dpi   OUT_PATH=/zc/test</p>      <p>${HPHOME}hadoop jar $JAR_PACKEGE \           -jobconf mapred.job.queue.name=shujuzu \           -jobconf stream.non.zero.exit.is.failure=false \           -inputformat SequenceFileAsTextInputFormat \           -numReduceTasks 30 \           -input $IN_PATH \           -output $OUT_PATH \           -file $MAP \           -mapper $MAP \           -file $RED \           -reducer $RED \           -file $UTIL \           -file ${MAP_FUNC}</p> </blockquote>  <p>error log:</p>  <blockquote>   <p>2015-09-21 12:54:39,006 INFO [IPC Server handler 26 on 52745] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1438082758366_8280_m_002703_3 is : 0.66699934   2015-09-21 12:54:40,636 FATAL [IPC Server handler 26 on 52745] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1438082758366_8280_m_002703_3 - exited : java.io.EOFException       at java.io.DataInputStream.readFully(DataInputStream.java:197)       at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:70)       at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:120)       at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2359)       at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2491)       at org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:82)       at org.apache.hadoop.mapred.SequenceFileAsTextRecordReader.next(SequenceFileAsTextRecordReader.java:66)       at org.apache.hadoop.mapred.SequenceFileAsTextRecordReader.next(SequenceFileAsTextRecordReader.java:35)       at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:199)       at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:185)       at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)       at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)       at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)       at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)       at java.security.AccessController.doPrivileged(Native Method)       at javax.security.auth.Subject.doAs(Subject.java:415)       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</p>      <p>2015-09-21 12:54:40,636 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1438082758366_8280_m_002703_3: Error: java.io.EOFException       at java.io.DataInputStream.readFully(DataInputStream.java:197)       at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:70)       at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:120)       at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2359)       at org.apache.hadoop.io.SequenceFile$Reader.next(SequenceFile.java:2491)       at org.apache.hadoop.mapred.SequenceFileRecordReader.next(SequenceFileRecordReader.java:82)       at org.apache.hadoop.mapred.SequenceFileAsTextRecordReader.next(SequenceFileAsTextRecordReader.java:66)       at org.apache.hadoop.mapred.SequenceFileAsTextRecordReader.next(SequenceFileAsTextRecordReader.java:35)       at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:199)       at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:185)       at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:52)       at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)       at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:450)       at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)       at java.security.AccessController.doPrivileged(Native Method)       at javax.security.auth.Subject.doAs(Subject.java:415)       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</p>      <p>2015-09-21 12:54:40,637 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1438082758366_8280_m_002703_3 TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP</p>      <p>2015-09-21 12:54:40,637 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1438082758366_8280_01_002370 taskAttempt attempt_1438082758366_8280_m_002703_3</p>      <p>2015-09-21 12:54:40,637 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1438082758366_8280_m_002703_3</p>      <p>2015-09-21 12:54:40,637 INFO [ContainerLauncher #3] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : NM04-305-BigData-172199.ctc.local:45454</p>      <p>2015-09-21 12:54:40,641 INFO [IPC Server handler 5 on 52745] org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents request from attempt_1438082758366_8280_r_000006_0. startIndex 2342 maxEvents 10000</p>      <p>2015-09-21 12:54:40,642 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1438082758366_8280_m_002703_3 TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP</p>      <p>2015-09-21 12:54:40,708 WARN [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete hdfs://ecloudtest/shujuzu/zjxc/fix/_temporary/1/_temporary/attempt_1438082758366_8280_m_002703_3</p>      <p>2015-09-21 12:54:40,709 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1438082758366_8280_m_002703_3 TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED</p> </blockquote>