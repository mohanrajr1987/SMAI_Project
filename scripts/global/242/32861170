<p>I have flat file with the following structure:</p>  <pre><code>key1|"value-001" key2|"value-002" key2|"value-003" key3|"value-004" key2|"value-005" key1|"value-006" key3|"value-007" </code></pre>  <p>I need to map this data file to key-value pairs where value will be list of values for one key, such as:</p>  <pre><code>key1:["value-001","value-006"] key2:["value-002","value-003","value-005"] key3:["value-004","value-007"] </code></pre>  <p>I need do this from Java code. As I understood from Spark Programming Guide this operation should be implemented by <code>sc.flatMapValues(..)</code>, <code>sc.flatMap(..)</code> or <code>sc.groupByKey(..)</code> but I don't know which one. How do I do this?</p>