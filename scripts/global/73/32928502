<p>I have a list containing approximately 30,000 words in a csv file and I have another csv file of words I'd like to fuzzy match against this list. This list contains 1 million words and some are spelled slightly differently than in the 30,000 word list. I have tried the following code but it takes forever to terminate. I need to be able to do this in a reasonable time </p>  <pre><code>from fuzzywuzzy fuzzy def fuzzy (a,b):     test = fuzz.ratio(a,b)     if test &gt;= 0.80:         return True     else:         return False   def replace(s):     for m in master:         if fuzzy(m.lower(),s.lower()) and len(m) &gt; 2:             return m     return s       def output():        list = []        fileObj = codecs.open( "word_list.csv", "rt")        raw = csv.DictReader(fileObj)        for row in raw:            x = row["Name"]            list.append((replace(row["Name"]))        return list         l = [output()]        new = list(zip(*l))        output_file = open('output.csv', 'w')        data = csv.writer(output_file)        data.writerows(new)        output_file.close() </code></pre>