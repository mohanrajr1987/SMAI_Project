<p>I have used the website below and am new to using R and would really appreciate some help to get going. <a href="http://rstudio-pubs-static.s3.amazonaws.com/39014_76f8487a8fb84ed7849e96846847c295.html" rel="nofollow">http://rstudio-pubs-static.s3.amazonaws.com/39014_76f8487a8fb84ed7849e96846847c295.html</a></p>  <p>This code works well for csv for with 100 rows(tested) but gives a error message for exceeding 1GB for the csv file with 50 0000 rows</p>  <pre><code>    library(tm)      library(RWeka) setwd("c:textanalysis/")      data &lt;- read.csv("postsdataset.csv", header=FALSE, stringsAsFactors=FALSE)      data &lt;- data[,2]      source("GenerateTDM.R") # generatetdm function in appendix     tdm.generate &lt;- function(string, ng){    # tutorial on rweka - http://tm.r-forge.r-project.org/faq.html    corpus &lt;- Corpus(VectorSource(string)) # create corpus for TM processing   corpus &lt;- tm_map(corpus, content_transformer(tolower))   corpus &lt;- tm_map(corpus, removeNumbers)    corpus &lt;- tm_map(corpus, removePunctuation)   corpus &lt;- tm_map(corpus, stripWhitespace)   # corpus &lt;- tm_map(corpus, removeWords, stopwords("english"))    options(mc.cores=1) # http://stackoverflow.com/questions/17703553/bigrams-   instead-of-single-words-in-termdocument-matrix-using-r-and-rweka/20251039#20251039   BigramTokenizer &lt;- function(x) NGramTokenizer(x, Weka_control(min = ng, max = ng)) # create n-grams   tdm &lt;- TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer))   # create tdm from n-grams   tdm   }    tdm &lt;- tdm.generate(data, 2) </code></pre>  <p>I want to clean text data (online posts collected in a csv file) and get rid of url, blank rows and usernames and explore my data and do clustering analysis for ngrams with tf/idf</p>  <p>how do i use source("GenerateTDM.R")?</p>