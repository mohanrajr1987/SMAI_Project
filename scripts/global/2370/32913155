<p>I am trying to build a sentiment analysis engine using python's sklearn package. the problem is analyzing Rotten Tomatoes reviews on this Kaggle Competition </p>  <p><a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews" rel="nofollow">https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews</a></p>  <p>the sentiments can take 5 possible values</p>  <p>I am using the following classifiers</p>  <ol> <li>Multinomial Naive Bayes</li> <li>Logistic Regression</li> <li>Stochastic Gradient Descent</li> </ol>  <p>Since these are all linear classifiers suited for binary classification, here are the steps that i have to take</p>  <ol> <li><p>Break up the training and test set into 5 parts, one part per sentiment. Lets say the possible values for the sentiment are a,b,c,d,e. So in part one of my data, i will have all the reviews, but the reviews that have sentiment 'a' will be marked as positive and all of the others will be marked as negative. Similarly i create other parts for the other sentiment values.</p></li> <li><p>Clean up the data in all 5 parts</p></li> <li><p>Create a pipeline and feed all the test set parts to my classifier, one after the other. I will store one result per part. So result of classifying part one is partOneRes and so on. Anything which is marked as positive in partOneRes belongs to sentiment 'a'. Similarly for other parts.</p></li> <li><p>Finally i would like to combine the results for all 5 parts. I will look at partOneRes. Anything that is marked positive will be changed to Sentiment 'a'. I will do similarly for all the other parts. Then i simply merge the results.</p></li> <li><p>It would have been ideal if i got no overlaps or duplicates. But i get a small number of duplicates, which is fine. I can add some logic to handle that.</p></li> <li><p>I would do this for all three classifiers and finally i want to find out which classifier give me the best results.</p></li> </ol>  <p>My problem is that I can see that there are many reviews which my classifier was not able to put in any category! Why would this happen? Could it be due to the small size of the dataset?</p>