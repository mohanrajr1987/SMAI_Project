<p>I've got a huge HDF5 dataset (10000,2048,2048) that I need to analyse (fitting the 10000 points on a 2048*2048 matrix), and I used parallel HDF5 in order to speed things up a little.</p>  <p>So I executed my python script using</p>  <pre><code>mpiexec -n 32 python myscript.py </code></pre>  <p>First, the CPU usage of each thread is surprisingly low at the beginning (mostly due to loading the 10000 points from one chunk of data) and then it starts to fit the data and CPU usage goes up to 100% and thread is finished within 2/3 days.</p>  <p>But then I launched it last week and there's only 1 thread that began to analyse data, seems like the other are still in the loading process (1-2% CPU load).</p>  <p>Thread that is running normally:</p>  <pre><code>1151 xxxxx     20   0 1058m  732  516 R 100.1  0.0   6878:13 python </code></pre>  <p>Thread that is slow:</p>  <pre><code>1142 xxxxx     20   0 1191m 228m 3028 D  1.7  0.2  97:38.97 python </code></pre>  <p>The only explanation I see is that other users are using the same server for other analysis but they are only using one/two core in total.</p>  <p>Any ideas about what could be the source of my problem?</p>  <p>Thank you.</p>