<p>I am newbie to spark and trying to understand spark concept with python. While using python to develop applications for spark, I get a bit confused with the way to get my data processed in parallel style. </p>  <p><strong>1</strong>.Everyone says that I don't need to worry about which node and how many nodeds will be invloved in processing my data encapsulated in RDD variables. Therefore, based on my best understanding, I believe what sparks cluster would do to the code below:</p>  <pre><code>a=sc.textFile(filename) b=a.filter(lambda x: len(x)&gt;0 and x.split("\t").count("9999-12-31")==0) c=b.collect() </code></pre>  <p>could be described as the following steps:</p>  <p><strong>(1)</strong> variable a will be saved as a RDD variable containing the    expected txt file content <br><strong>(2)</strong> Different Chunks of RDD a will be    broadcasted to different nodes in the cluster and filter method will    be conducted for each chunk in different node<br> <strong>(3)</strong> when collection    action is invoked, the results will be returned to the master from    different nodes and saved as a local variable c.</p>  <p>Is my description right? if not, what exactly will the procedure be? If I am right, what is the point to have parallelize method? Does the following code experience the same thing as that listed above?</p>  <pre><code>    a=sc.textFile(filename).collect()     b=sc.parallelize(a).filter(lambda x: len(x)&gt;0 and x.split("\t").count("9999-12-31"))     c=b.collect() </code></pre>  <p><strong>2</strong>.For the following code, could any guru please assure me if the sql query synatx would be proceeded in parallel by dividing the defined table into many partitions?</p>  <pre><code>a=sc.textFile(filename) b=a.filter(lambda x: len(x)&gt;0 and x.split("\t").count("9999-12-31")==0) parts=b.map(lambda x: x.split("\t")) records=parts.map(Row(r0=str(x[0]),r1=x[1],r2=x[2])) rTable=sqlContext.createDataFrame(records) rTable.registerTempTable("rTable") result=sqlContext.sql("select substr(r0,1,2), case when r1=1 then r1*100 else r1*10 end, r2 from rTable").collect() </code></pre>  <p>Great Thanks in advance!</p>