<p>I am working now with the randomForest package in R. To speed up the classification step, I was interested in performing the forest in parallel. For that, I have used the package 'foreach' in a similar way that it is indicated on the 'foreach' vignette. This consists in splitting the total number of trees by the number of cores you would like to use, and then combining them with the function 'combine' of the package 'randomForest':</p>  <pre><code>require(randomForest) require(foreach) require(doParallel) registerDoParallel(cores=CPUS) rf  &lt;- foreach::foreach(ntree=rep(ceiling(NTREE/CPUS), CPUS), .combine=randomForest::combine, .packages='randomForest') %dopar% {     randomForest::randomForest(x=t(Y), y=A, ntree=ntree, importance=TRUE, ...)     } </code></pre>  <p>I compared the results of the "parallel" forest with the forest generated in one core. The prediction capacity with the test set seems to be similar, but the 'importance' values are considerably reduced, and this affects the following steps of variable selection. </p>  <pre><code>imp &lt;- importance(rf,type=1) </code></pre>  <p>I would like to know why this happens, and if it is correct or there is any mistake. Thanks a lot!</p>