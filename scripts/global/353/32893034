<p>I have a Windows Service that has code similar to the following:</p>  <pre><code>List&lt;Buyer&gt;() buyers = GetBuyers(); var results = new List&lt;Result();  Parallel.Foreach(buyers, buyer =&gt; {     // do some prep work, log some data, etc.      // call out to an external service that can take up to 15 seconds each to return     results.Add(Bid(buyer));     }  // Parallel foreach must have completed by the time this code executes foreach (var result in results) {     // do some work } </code></pre>  <p>This is all fine and good and it works, but I think we're suffering from a scalability issue. We average 20-30 inbound connections per minute and each of those connections fire this code. The "buyers" collection for each of those inbound connections can have from 1-15 buyers in it. Occasionally our inbound connection count sees a spike to 100+ connections per minute and our server grinds to a halt.</p>  <p>CPU usage is only around 50% on each server (two load balanced 8 core servers) but the thread count continues to rise (spiking up to 350 threads on the process) and our response time for each inbound connection goes from 3-4 seconds to 1.5-2 minutes.</p>  <p>I suspect the above code is responsible for our scalability problems. Given this usage scenario (parallelism for I/O operations) on a Windows Service (no UI), is Parallel.ForEach the best approach? I don't have a lot of experience with async programming and am looking forward to using this opportunity to learn more about it, figured I'd start here to get some community advice to supplement what I've been able to find on Google.</p>