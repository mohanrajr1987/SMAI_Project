<p>I am trying to use the Spark Cassandra connector.</p>  <p>Here is my code:</p>  <pre><code>   JavaRDD&lt;UserStatistics&gt; rdd=CassandraJavaUtil.javaFunctions(sparkContext).cassandraTable(             ConfigStore.read("cassandra", "keyspace"), "user_activity_" + type).where("bucket =?",             date).select("user_id", "code").mapToPair(row -&gt; new Tuple2&lt;String, Integer&gt;(row             .getString("user_id"), 1)).reduceByKey((value1, value2) -&gt; value1 + value2).map(s -&gt;     {         List&lt;UserStatistics&gt; userStatistics = new ArrayList&lt;&gt;();         UserStatistics userStatistic = new UserStatistics();         userStatistic.setUser_id(s._1);         userStatistic.setStatistics_type(type);         long total = s._2;         int failureCount = 0;//s._2._2().iterator().next();         int selectedCount = 0; //s._2._2().iterator().next();         userStatistic.setTotal_count((int) total);         userStatistic.setFailure_count(failureCount);         userStatistic.setSelected_count(selectedCount);         userStatistics.add(userStatistic);         return userStatistic;     });     CassandraJavaUtil.javaFunctions(rdd).writerBuilder(ConfigStore.read("cassandra", "keyspace"),             "user_statistics",mapToRow(UserStatistics.class)).saveToCassandra(); </code></pre>  <p>After I execute this, it outputs the follow. It eventually throws a OOM exception for the driver. I am not sure why it is trying to send data to driver.</p>  <pre><code>Executor: Finished task 1007.0 in stage 0.0 (TID 1007). 84821 bytes result sent to driver 15/09/29 13:57:32 INFO TaskSetManager: Starting task 1016.0 in stage 0.0 (TID 1016, localhost, NODE_LOCAL, 2096 bytes) 15/09/29 13:57:32 INFO TaskSetManager: Finished task 1007.0 in stage 0.0 (TID 1007) in 78 ms on localhost (1009/640442) 15/09/29 13:57:32 INFO Executor: Running task 1016.0 in stage 0.0 (TID 1016) </code></pre>