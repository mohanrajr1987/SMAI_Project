<p>I'm running a simplistic application on Spark/Cassandra cluster. Since moving to a new environment (Spark 1.5 instead of 1.2 and minor Cassandra version upgrade too) substantial performance downgrade was observed (from 4 s. to 1-5 m. for same task and same amounts of data).</p>  <p>After initial investigation it seems, that for exactly same code from spark-driver's perspective, there are many more tasks generated (20+k, where it used to be up to 5) and logs on executor's end also reflect the same situation: </p>  <p>many sequential executions of the same query on different partitions:</p>  <pre><code>... CassandraTableScanRDD: Fetched 0 rows from x.y for partition 20324 in 0.138 s. CassandraTableScanRDD: Fetched 0 rows from x.y for partition 20327 in 0.058 s. CassandraTableScanRDD: Fetched 0 rows from x.y for partition 20329 in 0.053 s. ... </code></pre>  <p>where it used to be a single one:</p>  <pre><code>CassandraTableScanRDD: Fetched 905 rows from x.y for partition 0 in 2.992 s. </code></pre>  <p>Since application code is the same, I wonder what could possibly have caused such a difference in partitioning behavior and what can be done to remediate that?</p>  <p>NB! Setup of both environments if different, configuration is not shared/inherited.</p>  <p>Thanks.</p>