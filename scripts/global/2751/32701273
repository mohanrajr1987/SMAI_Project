<p>So I'm trying to implement stochastic gradient descent in CUDA, and my idea is to parallelize it similar to the way that is described in the paper <a href="http://arxiv.org/pdf/1012.1367.pdf" rel="nofollow">Optimal Distributed Online Prediction Using Mini-Batches</a></p>  <p>That implementation is aimed at MapReduce distributed environments so I'm not sure if it's optimal when using GPUs. </p>  <p>In short the idea is: at each iteration, calculate the error gradients for each data point in a batch (map), take their average by sum/reducing the gradients, and finally perform the gradient step updating the weights according to the average gradient. The next iteration starts with the updated weights.</p>  <p>The <a href="http://docs.nvidia.com/cuda/thrust/" rel="nofollow">thrust</a> library allows me to perform a reduction on a vector allowing me for example to sum all the elements in a vector.</p>  <p>My question is: How can I sum/reduce an array of vectors in CUDA/thrust? The input would be an array of vectors and the output would be a vector that is the sum of all the vectors in the array (or, ideally, their average).</p>