<p>My <em>3D Laplacian</em> solver works. I obtain a power of 350 Gflop/s, I'm trying to upgrade it to have better performance with twice as much blocks. However, performances still being 350 Gflop/s:</p>  <pre><code> #include &lt;iostream&gt;  #include &lt;sys/time.h&gt;  #include &lt;cuda.h&gt;  #include &lt;ctime&gt;  #include"res3dcb.cuh"  #include &lt;math.h&gt;  using namespace std;   // Constant statement.  const int blocksize=32;  const int N=128;  const int size=(N+2)*(N+2)*(N+2)*sizeof(float);   // Let's start the main program.  int main(void) {   // Variable statement.  float time1,time2,time3;  float *x_d, *y_d;   float *x,*y;   float gflops;  float NumOps;  int power=4; // You can change power as you prefer (but keep 2^x)   // Init x and y.   x = new float[size];  y = new float[size];   for (int k=1;k&lt;N+1;k++)     for (int i=1;i&lt;N+1;i++)          for (int j=1;j&lt;N+1;j++) {              x[k*(N+2)*(N+2)+i*(N+2)+j]=cos(i+j+k);         }   // Shadow cases.  for (int k=1;k&lt;N+1;k++) {     for (int i=1;i&lt;N+1;i++) {        x[k*(N+2)*(N+2)+i*(N+2)]=x[k*(N+2)*(N+2)+i*(N+2)+1];        x[k*(N+2)*(N+2)+i*(N+2)+N+1]=x[k*(N+2)*(N+2)+i*(N+2)+N];}      for (int j=0;j&lt;N+2;j++) {        x[k*(N+2)*(N+2)+j]=x[k*(N+2)*(N+2)+(N+2)+j];        x[k*(N+2)*(N+2)+(N+1)*(N+2)+j]=x[k*(N+2)*(N+2)+N*(N+2)+j];}   for (int i=0;i&lt;N+2;i++)      for (int j=0;j&lt;N+2;j++) {         x[(N+2)*i+j]=x[(N+2)*(N+2)+(N+2)*i+j];         x[(N+1)*(N+2)*(N+2)+(N+2)*i+j]=x[(N+2)*(N+2)*N+(N+2)*i+j];     }   // Display of initial matrix.  int id_stage=-2;  while (id_stage!=-1) {      cout&lt;&lt;"Which stage do you want to display? (-1 if you don't want to diplay another one)"&lt;&lt;endl;      cin&gt;&gt;id_stage;      cout&lt;&lt;endl;       if (id_stage != -1) {     cout&lt;&lt;"Etage "&lt;&lt;id_stage&lt;&lt;" du cube :"&lt;&lt;endl;     for (int i=0;i&lt;N+2;i++) {         cout&lt;&lt;"| ";         for (int j=0;j&lt;N+2;j++) {cout&lt;&lt;x[id_stage*(N+2)*(N+2)+i*(N+2)+j]&lt;&lt;" ";}         cout&lt;&lt;"|"&lt;&lt;endl;         }          cout&lt;&lt;endl;      }  }   // CPU to GPU.  cudaMalloc( (void**) &amp; x_d, size);  cudaMalloc( (void**) &amp; y_d, size);   cudaMemcpy(x_d, x, size, cudaMemcpyHostToDevice) ;  cudaMemcpy(y_d, y, size, cudaMemcpyHostToDevice) ;   // Solver parameters.  dim3 dimGrid(power*N/blocksize, power*N/blocksize);  dim3 dimBlock(blocksize, blocksize);   // Solver loop.  time1=clock();   res2d&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(x_d, y_d, N, power);    time2=clock();  time3=(time2-time1)/CLOCKS_PER_SEC;   // Power calculation.  NumOps=(1.0e-9)*N*N*N*7;  gflops = ( NumOps / (time3));   // GPU to CPU.  cudaMemcpy(y, y_d, size, cudaMemcpyDeviceToHost);  cudaFree(x_d);  cudaFree(y_d);   // Display of final matrix.  id_stage=-2;  while (id_stage!=-1) {     cout&lt;&lt;"Which stage do you want to display? (-1 if you don't want to diplay another one)"&lt;&lt;endl;     cin&gt;&gt;id_stage;     cout&lt;&lt;endl;       if (id_stage != -1) {         cout&lt;&lt;"Etage "&lt;&lt;id_stage&lt;&lt;" du cube :"&lt;&lt;endl;         for (int i=0;i&lt;N+2;i++) {             cout&lt;&lt;"| ";             for (int j=0;j&lt;N+2;j++) {cout&lt;&lt;y[id_stage*(N+2)*(N+2)+i*(N+2)+j]&lt;&lt;" ";}             cout&lt;&lt;"|"&lt;&lt;endl;          }         cout&lt;&lt;endl;      }  }   cout&lt;&lt;"Time : "&lt;&lt;time3&lt;&lt;endl;  cout&lt;&lt;"Gflops/s : "&lt;&lt;gflops&lt;&lt;endl;   } </code></pre>  <p>Where:</p>  <pre><code>__ global__ void res2d(volatile float* x, float* y, int N, int power)  {     int i = threadIdx.x + blockIdx.x*(blockDim.x);     int j = threadIdx.y + blockIdx.y*(blockDim.y);     int id,jd;      #pragma unroll //Now let's recude the number of operation per block     for (int incr=1; incr&lt;power+1; incr++) {         if (i&gt;(incr-1)*N &amp;&amp; i&lt;incr*N &amp;&amp; j&gt;(incr-1)*N &amp;&amp; j&lt;incr*N) {             #pragma unroll             for (int k=(incr-1)*(N/power) ; k&lt;incr*N/power ; k++) {                 id=i-(incr-1)*N;                 jd=j-(incr-1)*N;                 y[(N+2)*(N+2)*(k+1)+(N+2)*(id+1)+jd+1] = x[(N+2)*(N+2)*(k+1)+(N+2)*(id+2)+jd+1]                                                         + x[(N+2)*(N+2)*(k+1)+(N+2)*id+jd+1]                                                         + x[(N+2)*(N+2)*(k+1)+(N+2)*(id+1)+jd+2]                                                         + x[(N+2)*(N+2)*(k+1)+(N+2)*(id+1)+jd]                                                         + x[(N+2)*(N+2)*(k+2)+(N+2)*(id+1)+jd+1]                                                         + x[(N+2)*(N+2)*k+(N+2)*(id+1)+jd+1]                                                         - 6*x[(N+2)*(N+2)*(k+1)+(N+2)*(id+1)+jd+1];             }            }     } } </code></pre>  <p>With parameters:</p>  <pre><code>dimGrid(power * N/blocksize, power * N/blocksize) &amp; dimBlock(blocksize, blocksize) </code></pre>  <h2>Questions:</h2>  <ol> <li><p>If <code>power</code>= <code>2</code>,<code>4</code> or <code>8</code>, number of operations per block is divided by <code>2</code>,<code>4</code> or <code>8</code>. But it's not faster. Why?</p></li> <li><p>Is it useless to reduce the number of operation per block?</p></li> </ol>  <p>Thanks in advance for your help.</p>