<p>To be distinguished from "shared memory" in the CUDA terminologies. The CUDA documents declared that the compiler would do automatically perform registers spilling if the variable is large or the SM run out of resource. They declared this memory space as "local memory", which is physically in the global memory but private to each thread.</p>  <p>I tested the performance in these three cases: 1) leaving the variables in the private space, thus the compiler would automatically do the register spilling. 2) put the data in the global memory, index elements using threadID, without memory coalescing. 3) same as 2), but with memory coalescing.</p>  <p>The result is that even 3) is slower than the case 1). </p>  <p>I don't know why this happen.</p>