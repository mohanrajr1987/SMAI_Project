<p>I am working on parallelizing a C code using CUDA. What I have figured out is that we can do our computations in the following pattern : <a href="http://i.stack.imgur.com/06WQE.png" rel="nofollow"><img src="http://i.stack.imgur.com/06WQE.png" alt="computational pattern"></a></p>  <p>Therefore, we can compute only one element labelled '1' in first step, only after the first element's computation is done we can start computing the next two diagonal elements labelled '2', as we have data dependency. So on and so forth for other elements ... </p>  <p>The approach that we have taken to solve this problem is to assign a thread to each row, where each one of them execute <code>__syncthreads()</code> at the end of each step to achieve the aforementioned synchronization.</p>  <p>But, <code>__syncthreads()</code> takes a lot of time. Is there any alternate solution to this issue.</p>  <p><strong>EDIT 1:</strong> The dependency pattern for computing each element <code>X</code> is as follows :</p>  <p><a href="http://i.stack.imgur.com/S1INw.png" rel="nofollow"><img src="http://i.stack.imgur.com/S1INw.png" alt="5 point stencil"></a></p>  <p>here, element <code>X</code> requires the values of red and green coloured elements. It is dependent only on the elements coloured red (which are computed in the previous iteration).</p>  <p>Thanks in advance.</p>