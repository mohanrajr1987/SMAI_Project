<p>I'm working on a script that lets me fetch the "solidfiles.com" links from certain website. I have got all the href links. But, I'm failing to keep only solidfiles.com links using python.</p>  <p><a href="https://animetosho.org/view/jacobswaggedup-kill-la-kill-bd-1280x720-mp4-batch.n677876" rel="nofollow">This is the website I'm trying to fetch links from</a></p>  <p>This is my current script :-</p>  <pre><code>import re import requests from bs4 import BeautifulSoup import os import fileinput  Link = 'https://animetosho.org/view/jacobswaggedup-kill-la-kill-bd-1280x720-mp4-batch.n677876' q = requests.get(Link) soup = BeautifulSoup(q.text) #print soup subtitles = soup.findAll('div',{'class':'links'}) #print subtitles   with  open("Anilinks.txt", "w") as f:     for link in subtitles:         x = link.find_all('a', limit=26)         for a in x:             url = a['href']             f.write(url+'\n') </code></pre>  <p>With this, I have written all the links in the text file named "Anilinks.txt". I can't seem to keep only solidfiles links. Any hint would be great.</p>