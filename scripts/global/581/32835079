<p>I'm using dHash (<a href="http://www.hackerfactor.com/blog/index.php?url=archives/529-Kind-of-Like-That.html" rel="nofollow">http://www.hackerfactor.com/blog/index.php?url=archives/529-Kind-of-Like-That.html</a>) in a veeery large set of images.  The default resize size is 8 pixels:</p>  <pre><code>def dhash(image, hash_size=8):     """     Difference Hash computation.     following http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html     @image must be a PIL instance.     """     image = image.convert("L").resize((hash_size + 1, hash_size), Image.ANTIALIAS)     pixels = numpy.array(image.getdata(), dtype=numpy.float).reshape((hash_size + 1, hash_size))     # compute differences     diff = pixels[1:, :] &gt; pixels[:-1, :]     return ImageHash(diff) </code></pre>  <p>If we apply this algorithm do a large number of images do I not will get collisions due to the short hash fingerprint?</p>  <p>What would be the best hash_size? Is not more accurate as larger is the hash_size? Is it 8 because some specific reason?</p>  <p>Cheers</p>