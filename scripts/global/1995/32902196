<p>We have configured Spark SQL(1.3.2) to work on top of Hive and we use Beeline to create the tables.</p>  <p>I was trying to create a table with BIGINT datatype.However I see that the table is getting created with INT datatype when I use the below command</p>  <pre><code>CREATE TEMPORARY TABLE cars (blank bigint) USING com.databricks.spark.csv OPTIONS (path "cars.csv", header "false") </code></pre>  <p>However when I use the command below I am able to create a table with bigint datatype</p>  <pre><code>CREATE TABLE cars(blank bigint) </code></pre>  <p>Can you let me know how can I create a tableBIGINT datatype using first method</p>  <p>Is it because of this</p>  <p>"Integral literals are assumed to be INT by default, unless the number exceeds the range of INT in which case it is interpreted as a BIGINT, or if one of the following postfixes is present on the number."</p>  <p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-IntegralTypes(TINYINT,SMALLINT,INT,BIGINT)" rel="nofollow">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types#LanguageManualTypes-IntegralTypes(TINYINT,SMALLINT,INT,BIGINT)</a> </p>