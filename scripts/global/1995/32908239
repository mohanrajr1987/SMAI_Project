<p>I'm using libhdfs to write large binary files. It works fine but for one problem. Even though I specify a 256K buffer size in the hdfsOpen call and call hdfsRead with a 256k data buffer, HDFS will read (or write) only 128k at a time.</p>  <p>Can that limit be changed anywhere? Can I read/write more than 128k at a time?</p>  <p><strong>Edit:</strong> Never mind. I misread the hdfsOpen API. The fourth argument is the maximum size of the buffer you will read/write. That is different from the last argument which sets the block size. I had the buffer size set to zero which gave me the default value of 128K.</p>  <p>For example:</p>  <p>fd = hdfsOpenFile(hdfs, path, O_WRONLY|O_CREAT|O_TRUNC, 1048576, 0, 1048576);</p>  <p>I specified 1048576 for the buffer size and 1048576 for the block size. This lets me write a page of data that will fit into a single block.</p>