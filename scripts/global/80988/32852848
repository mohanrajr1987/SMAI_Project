<h1>Preamble</h1>  <p>When a webpage is dynamically generated by javascript based on a hashbang (<code>#!</code>) url, google has a hard time indexing it, and cannot provide search results or automatically accept it for services like AdSense.</p>  <p>One solution is to introduce the <code>_escaped_fragment_</code> GET variable and serve static <a href="https://developers.google.com/webmasters/ajax-crawling/docs/specification" rel="nofollow">html snapshots</a> that represent the dynamic content.</p>  <p>This can be done manually by visiting the website in Chrome, copy the DOM from <em>Developer Console > Elements</em>, save it to a <code>html</code> file, and serve these html files when the hashbang is requested in the <code>_escaped_fragment_</code>.</p>  <h1>Problem</h1>  <p>This is doable for the main pages, but trying to manually follow all the links and save the DOM once all the scripts have executed is nearly undoable.</p>  <p>Furthermore, this process should be repeated once in a while so the snapshots don't deviate too much from the actual website.</p>  <h1>Question</h1>  <p>I am wondering if there is a tool or chrome extension that automates this. Open a link, let the javascript generate the DOM, and save the DOM to a file named after the hashbang.</p>  <p>Ideally this would be simple enough to do from the terminal so this can be automated using <code>Grunt</code> on deploy.</p>