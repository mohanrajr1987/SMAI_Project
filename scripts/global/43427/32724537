<p>The API should allow arbitrary HTTP get requests containing URLs the user wants scraped, and then Flask should return the results of the scrape.</p>  <p>The following code works for the first http request, but after twisted reactor stops, it won't restart. I may not even be going about this the right way, but I just want to put a RESTful scrapy API up on Heroku, and what I have so far is all I can think of.</p>  <p>Is there a better way to architect this solution? Or how can I allow <code>scrape_it</code> to return without stopping twisted reactor (which can't be started again)?</p>  <pre><code>from flask import Flask import os import sys import json  from n_grams.spiders.n_gram_spider import NGramsSpider  # scrapy api from twisted.internet import reactor import scrapy from scrapy.crawler import CrawlerRunner from scrapy.xlib.pydispatch import dispatcher from scrapy import signals  app = Flask(__name__)   def scrape_it(url):     items = []     def add_item(item):         items.append(item)      runner = CrawlerRunner()      d = runner.crawl(NGramsSpider, [url])     d.addBoth(lambda _: reactor.stop()) # &lt;&lt;&lt; TROUBLES HERE ???      dispatcher.connect(add_item, signal=signals.item_passed)      reactor.run(installSignalHandlers=0) # the script will block here until the crawling is finished       return items  @app.route('/scrape/&lt;path:url&gt;') def scrape(url):      ret = scrape_it(url)      return json.dumps(ret, ensure_ascii=False, encoding='utf8')   if __name__ == '__main__':     PORT = os.environ['PORT'] if 'PORT' in os.environ else 8080      app.run(debug=True, host='0.0.0.0', port=int(PORT)) </code></pre>