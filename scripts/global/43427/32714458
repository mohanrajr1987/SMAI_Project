<p>My  <code>scrapy crawl</code> command works well<br> But when I want to deploy scrapyd ,I met problems</p>  <pre><code>scrapyd-deploy &lt;target&gt; -p &lt;project&gt; </code></pre>  <p>I try on my mac and a remote server(centos),but both had error</p>  <pre><code>Deploying to project "start" in http://localhost:6800/addversion.json Server response (200): {"status": "error", "message": "ImportError:  No module named project.models ", "node_name": "MacBook-Air.local"} </code></pre>  <p>I think it's because scrapyd can't find django path  </p>  <p>I use      Django==1.7.10     Scrapy==1.0.3</p>  <p>Here is my structue </p>  <pre><code>mysite ├── manage.py ├── project │   ├── __init__.py │   ├── models.py │   ├── tests.py │   └── views.py └── mysite │   ├── __init__.py │   ├── settings.py │   ├── urls.py │   └── wsgi.py │     └── scrapypjt       └── things             ├── scrapy.cfg             ├── setup.py                     └── things                 ├── __init__.py                 ├── settings.py                 ├── items.py                 └── pipelines.py                    └── spiders </code></pre>  <p>Here is my scrapy settings file :</p>  <pre><code>import sys, os django_path = os.path.join(os.path.dirname(__file__),"../../../") sys.path.append(os.path.abspath(django_path)) os.environ['DJANGO_SETTINGS_MODULE'] = 'mysite.settings' </code></pre>  <p>What else should I setting??</p>