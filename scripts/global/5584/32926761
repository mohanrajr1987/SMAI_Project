<p>I have a project in mind where two displays are connected to the same application. The first display does the processing and renders the scene, while sending instructions to the second display over Wifi which also renders a part of the scene.</p>  <p>I would like this to be easy to integrate in Unity projects which run on Android and iOS platforms (iOS being one of the receiving displays). </p>  <p>I was thinking this would be possible by streaming video, but there would be a noticeable delay and more importantly heavy processing involved.</p>  <p>My second thought would be to stream OpenGL calls to the second device, which would at least remove the heavy processing. This has been done before with projects called Chromium and ClusterGL.</p>  <p>I am wondering however if Unity can allow for such an application or that the OpenGL calls are obscured. Is this possible with the Native Plugin Interface (<a href="http://docs.unity3d.com/Manual/NativePluginInterface.html" rel="nofollow">http://docs.unity3d.com/Manual/NativePluginInterface.html</a>)? </p>  <p><em>Edit</em>: As a followup, does Unity allow for multiple rendering contexts?</p>