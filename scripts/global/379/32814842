<p>I have text file containing images and I have a directory where I wanted to save my images.</p>  <pre><code>import os import urllib import sys   def normalize(url):    url = url.split("/")[-1]    return url.split("\n")[0]  def main():    out_dir = "Workspace/cnf/img"      with open('cnf/image_flower.txt') as url_array:     for url in url_array:         try:            urllib.urlretrieve(url, os.path.join(out_dir, normalize(url)))          except Exception as e :             print "Exception|",e,"|",url  print("Images Downloaded") </code></pre>  <p>main()</p>  <p>I am getting the images.But I am facing the following issues 1.I want to catch all the http error codes and print it like page not found and all kind of error.which my code is not able to print. 2.I have around 1,00,000 urls.So my code is taking a lot of time.</p>  <p>Could you please suggest me a better way to handle it</p>