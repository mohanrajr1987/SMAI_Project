<p>I'm having trouble adding cross validation to the tree model I have created in R. I was able to produce this tree model using given supplied data. We are looking at a binary variable whether a customer from a telecommunication service to churn or not (churn as in change companies from vodafone to telecom). Here is the code for creating linear and tree models.The cutoffplot and classification metric files just produces a graph with accuracy, sensitivity and specificity values.</p>  <pre><code>source("cutoff-plot.R") source("classification-metrics.R") library(tree)   ## credit risk as good or bad (bad is primary because this is what interests us) negative.label &lt;- "no" positive.label &lt;- "yes" class.labels &lt;- c(negative.label, positive.label) churn.data &lt;- read.csv("churn2.csv")  ##We need to make sure that the class in our data set is properly set up ##in that our positive class label is clearly identified churn.data$Churn &lt;- factor(   as.numeric(churn.data$Churn==positive.label),   levels=0:1, labels=class.labels)  ##build prediction models as before in our regression problem: ## note change in first model because we are using generalized linear model for logistic regression linear.model &lt;- glm(Churn ~ .,                     churn.data, family=binomial) tree.model &lt;- tree(Churn ~ ., churn.data)  ##probability of an instance belonging to the positive class p.linear &lt;- predict(linear.model,                     churn.data, type="response") p.tree &lt;- predict(tree.model, churn.data)[, 2]  ##our class estimates through thresholding, we pick a threshold, say 0.5(default), and any prediction probability  ## that we encounter over this value is labelled as a positive example, otherwise it is labelled negative yhat.linear &lt;- compute.yhat(p.linear) yhat.tree &lt;- compute.yhat(p.tree)  ##We now have predictions of class labels. We can now compare these to the observed class labels in our data set,  ## and from these comparisons obtain performance measures. ##summary.stats is a function that we've provided for you to easily compute the accuracy,  ## sensitivity, and specificity statistics for your models y &lt;- churn.data$Churn linear.stats &lt;- summary.stats(y, yhat.linear) tree.stats &lt;- summary.stats(y, yhat.tree)  cutoff.plot(p.linear, y) cutoff.plot(p.tree, y)  tree.stats linear.stats  yhat.linear &lt;- compute.yhat(p.linear, threshold=0.16) yhat.tree &lt;- compute.yhat(p.tree, threshold=0.12)  y &lt;- churn.data$Churn linear.stats &lt;- summary.stats(y, yhat.linear) tree.stats &lt;- summary.stats(y, yhat.tree)  cutoff.plot(p.linear, y) cutoff.plot(p.tree, y)  tree.stats linear.stats </code></pre>  <p>Here is the code for classification-metrics files.</p>  <pre><code>compute.yhat &lt;- function(p, threshold=0.5, labels=class.labels) {   factor(as.numeric(p &gt; threshold), levels=0:1, labels=labels) }  specificity &lt;- function(class, yhat) {   conf &lt;- table(class, yhat)   conf[1,1] / sum(conf[1, ]) }  sensitivity &lt;- function(class, yhat) {   conf &lt;- table(class, yhat)   conf[2,2] / sum(conf[2, ]) }  accuracy    &lt;- function(class, yhat) {   sum(diag(table(class, yhat))) / length(class) }      summary.stats &lt;- function(class, yhat) {       c(accuracy=accuracy(class, yhat),         sensitivity=sensitivity(class, yhat),         specificity=specificity(class, yhat))     } </code></pre>  <p>I also have a R script for using cross validation in regression models but the variable is numerics and I tried converting the script but i think the difference in variable type numerics and binary is causing problems. So i have no idea what to do.</p>  <pre><code>library(MASS)  library(tree) data.set &lt;- Boston f &lt;- medv ~ .  ## cv 10 folds n.folds &lt;- 10  fold.idx &lt;- sample(rep(1:n.folds, length=nrow(data.set)))  ##create two prediction vectors yhat.linear &lt;- rep(NA, nrow(data.set)) yhat.tree &lt;- rep(NA, nrow(data.set))  ##build a model for each fold, and use that to predict the required values for (k in 1:n.folds) {   fold &lt;- which(fold.idx == k)   linear.model &lt;- lm(f, data.set[-fold, ])   tree.model &lt;- tree(f, data.set[-fold, ])   yhat.linear[fold] &lt;- predict(linear.model, data.set[fold, ])   yhat.tree[fold] &lt;- predict(tree.model, data.set[fold, ]) }   y &lt;- data.set$medv rmse.linear &lt;- sqrt(mean((y-yhat.linear)^2)) rmse.tree &lt;- sqrt(mean((y-yhat.tree)^2)) </code></pre>