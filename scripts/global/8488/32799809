<p>I'm trying to loop through a script that parses tables with Beautiful Soup in Python 2.7.</p>  <p>The first table parse works and produces the expected results.  The second loop produces exactly the same results as the first loop.<br> Additional details:</p>  <ul> <li>If I manually use the url that the second loop used to parse, I get the intended page that I want to scrape.  There is a little delay in refresh.</li> <li>I use this on other websites and the loop works as intended.</li> </ul>  <p>Here is the script:</p>  <pre><code>    import urllib2     import csv     from bs4 import BeautifulSoup # latest version bs4      week = raw_input("Which week?")     week = str(week)     data = []     first = "http://fantasy.nfl.com/research/projections#researchProjections=researchProjections%2C%2Fresearch%2Fprojections%253Foffset%253D"     middle = "%2526position%253DO%2526sort%253DprojectedPts%2526statCategory%253DprojectedStats%2526statSeason%253D2015%2526statType%253DweekProjectedStats%2526statWeek%253D"     last = "%2Creplace"     page_num = 1     for page_num in range(1,3):         page_mult = (page_num-1) * 25 +1         next = str(page_mult)         url = first + next + middle + week + last     print url #I added this in order to check my output     html = urllib2.urlopen(url).read()     soup = BeautifulSoup(html,"lxml")     table = soup.find('table', attrs={'class':'tableType-player hasGroups'})     table_body = table.find('tbody')      rows = table_body.find_all('tr')     for row in rows:         cols = row.find_all('td')         cols = [ele.text.strip() for ele in cols]         data.append([ele for ele in cols if ele]) # Get rid of empty values     b = open('NFLtable.csv', 'w')     a = csv.writer(b)     a.writerows(data)     b.close()     page_num =page_num+1     print data </code></pre>