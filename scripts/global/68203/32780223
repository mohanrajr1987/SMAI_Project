<p>I'm writing a scraping code using selenium and PhantomJS. It works perfectly on local machine but as i run the code from AWS it works for a while and freezes all of a sudden.</p>  <p>Here is my code :</p>  <pre><code># -*- coding: utf-8 -*-  from scrapy.spider import BaseSpider from selenium import webdriver from selenium.webdriver.common.keys import Keys import time import csv import re from selenium.webdriver.common.action_chains import ActionChains from selenium.webdriver.support.ui import WebDriverWait   class DukeSpider(BaseSpider):   name = "dspider"   allowed_domains = ["dukemedicine.org"]   start_urls = ["http://www.dukemedicine.org/find-doctors-physicians"]  #hlor     def __init__(self):     self.driver = webdriver.PhantomJS(service_args=['--ssl-protocol=any'])     self.driver.maximize_window()     print 'here'     def parse(self, response):       b = open('doc_data_duke.csv', 'a')     a = csv.writer(b, lineterminator='\n')       self.driver.get(response.url)     time.sleep(10)     wait = WebDriverWait(self.driver, 10)             click = self.driver.find_element_by_xpath("//span[@id='specialty']")     click.click()     click_again = self.driver.find_element_by_xpath(         "//ul[@class='doctor-type']/li[@class='ng-binding ng-scope'][2]")      click_again.click()     time.sleep(15)      act = ActionChains(self.driver)     act.move_to_element(self.driver.find_element_by_id('doctor-matrix-section')).click()     print 'now here'      for i in range(0, 10):         #self.driver.find_element_by_xpath("//div[@id='doctor-matrix-section']").send_keys(Keys.PAGE_DOWN)          act.send_keys(Keys.PAGE_DOWN).perform()         time.sleep(1)         print 'hello'         print i         i += 1      links = self.driver.find_elements_by_xpath("//div[@class = 'result-information']/div[@class='name']/a")      for l in links:         print l         doc_list = l.get_attribute('href')         if re.match(r'https:\/\/www\.dukemedicine\.org\/find-doctors-physicians\/#!\/(.*)', doc_list):             print doc_list             dr = webdriver.PhantomJS(service_args=['--ssl-protocol=any'])             dr.maximize_window()              dr.get(doc_list)  #This is where it freezes              try:                 name_title = dr.find_element_by_xpath('//div[@class="header1 ng-binding"]').text                 name_titles = name_title.split(",", 1)                 name = name_titles[0].encode('utf-8')                  title = name_titles[1]                 print name.encode('utf-8')                 title = title[1:].encode('utf-8')                 print title.encode('utf-8')             except:                 name = ''                 title = '' </code></pre>  <p>The code works for some websites in the list but freezes all of a sudden. Python version : 2.7.6 Selenium version : 2.47.3 PhantomJs version: 1.9.0</p>