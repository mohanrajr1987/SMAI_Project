<p>I need to take elements identified by xpath in a "Infinite Scroll" web page like <a href="https://medium.com/top-100/december-2013" rel="nofollow">this</a>.  The problem is that when i use Selenium with webdriver PhantomJS it takes only some links, the first links loaded after the page is loaded. I try to increase the <em>time.sleep()</em> or insert more of there in the code but not works. If i use Firefox like a webdriver it works well.</p>  <p>It's possibile sove this problem and improve my code? Maybe not using time event but looking something that can tell if go down on the page or not.</p>  <p>Thanks and Greetings   </p>  <pre><code>import re import mechanize from pydblite import Base from selenium import webdriver import platform import codecs import scrapy   import time from selenium.webdriver.common.keys import Keys  class getFrom(object):    def scrapying(self):     print platform.system()           #browser = webdriver.Firefox()         browser = webdriver.PhantomJS(executable_path='/usr/local/bin/node_modules/phantomjs/lib/phantom/bin/phantomjs')        browser.get("https://medium.com/top-100/december-2013")     time.sleep(5)      elem = browser.find_element_by_tag_name("body")      no_of_pagedowns = 200      while no_of_pagedowns:         elem.send_keys(Keys.PAGE_DOWN)         time.sleep(0.02)         no_of_pagedowns-=1      #Qui ci dovrebbe essere lo spider      post_elems = browser.find_elements_by_class_name("graf--h2")      #Fine Spider      for post in post_elems:         print post.text      browser.quit()  myClassObject = getFrom() myClassObject.scrapying() </code></pre>