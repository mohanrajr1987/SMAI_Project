<p>I have a json file that looks like this:</p>  <pre><code>[     {         "id" : "0001"         "label" : "A"         "properties": [             "a",             "b",             "c"         ]     },     {         "id" : "0002"         "label" : "B"         "properties": [             "b",              "d",             "e"         ]      } ] </code></pre>  <p>This dataset is quite big, it has 20 different labels, 9000 distinct properties and tens of thousands of distinct ids.</p>  <p>I'm processing this file with python and want to use scikit-learn to build a model that can make predictions.</p>  <p>How do I go about and make sure that I end up with encoded features that look somewhat like this:</p>  <pre><code>id,   label, a, b, c, d, e 0001, A,     1, 1, 1, 0, 0 0002, B,     0, 1, 0, 1, 1 </code></pre>  <p>I tried using pandas, patsy and a few other things but couldn't get a proper dataset out of the json. I could of course write everything manually but that would a) be much slower to process and b) doesn't give me any insight into these tools (pandas, numpy, scipy, scikit-learn)</p>