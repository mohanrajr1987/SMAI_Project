<p>When the following code is run, I get the following message two times in a row (though it appears to run successfully):</p>  <p>C:\Users\mike\Anaconda3\lib\site-packages\ipykernel__main__.py:123: SettingWithCopyWarning:  A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead</p>  <p>See the the caveats in the documentation: <a href="http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy" rel="nofollow">http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy</a></p>  <p>I suspect one of the warnings are referring to:</p>  <pre><code>ascombnbDup2 = ascombnbDup2.sort(['TestStartDate','TestStandardError','TestRITScore','TestDurationMinutes'], ascending=[1,0,1,1]) dups2use = ascombnbDup2.groupby(['TermName', 'SchoolName', 'StudentID', 'Discipline']).tail(1) </code></pre>  <p>but I'm not sure. Can anyone identify the two areas for which these warnings are being generated?</p>  <pre><code>##Concatenate fields and check for duplicates Sframe["TermSchoolStudent"]=Sframe["TermName"]+Sframe["SchoolName"]+\ Sframe["StudentID"].map(str)      Sframe['dup_check_1'] = Sframe.duplicated(subset = ['TermName', 'SchoolName', 'StudentID'], take_last = False)     #duplicates only column     Sframe['dup_check_2'] = Sframe.duplicated(subset = ['TermName', 'SchoolName', 'StudentID'], take_last = True)     #remove both from Sframe (df)     Sframe = Sframe[(Sframe['dup_check_1'] == False) &amp; (Sframe['dup_check_2'] == False)]     #delete duplicate checking columns     del Sframe['dup_check_1'], Sframe['dup_check_2']   #next merge data frames as noted ascomb=pd.merge(Sframe, Aframe, on=['TermName', 'SchoolName', 'StudentID'], how='outer')   #ascombnb: THESE ARE THE MERGED, NON-BLANK ASSESSMENTS AND STUDENTS RECORDS ascombnoa = ascomb[pd.isnull(ascomb['Discipline'])] ascombnoa.to_csv(str(out_folder)+'\Exceptions\Students_Without_Assessments '+str(st)+'.csv', sep=',') ascombnos = ascomb[pd.isnull(ascomb['Grade'])] ascombnos.to_csv(str(out_folder)+'\Exceptions\Assessments_Without_Students '+str(st)+'.csv', sep=',') </code></pre>  <p>...</p>  <pre><code>#ascombnb: assessments and students combined, no blanks ascombnb = ascomb[pd.notnull(ascomb['Discipline']) &amp; pd.notnull(ascomb['Grade'])] print ("\n") print ("%d matched records (proceeding with these only)..." % len(ascombnb))       ascombnb['dup_check_1'] = ascombnb.duplicated(subset = ['TermName', 'SchoolName', 'StudentID', 'Discipline'], take_last = False) #duplicates only column ascombnb['dup_check_2'] = ascombnb.duplicated(subset = ['TermName', 'SchoolName', 'StudentID', 'Discipline'], take_last = True) #remove both from ascombnb and save as asnds (asessments and students, no duplicates) (df) asnds = ascombnb[(ascombnb['dup_check_1'] == False) &amp; (ascombnb['dup_check_2'] == False)] #delete duplicate checking columns del ascombnb['dup_check_1'], ascombnb['dup_check_2'] del asnds['dup_check_1'], asnds['dup_check_2']   asnds['Repeated'] = 'no'  #ascombnbDup2: THESE ARE THE MERGED, NON-BLANK ASSESSMENTS AND STUDENTS RECORDS THAT ARE THE DUPLICATED AND DUPLICATE RECORDS asnds2 = asnds[['TermName', 'SchoolName', 'StudentID', 'Discipline', 'Repeated']] ascombnbDup=pd.merge(ascombnb, asnds2, on=['TermName', 'SchoolName', 'StudentID', 'Discipline'], how='left') ascombnbDup2=ascombnbDup[(ascombnbDup['Repeated'] != 'no')]  print ('\n') print ('%d rows of duplicate and duplicated records found. From these, I will select one score per student.' % len(ascombnbDup2))  ascombnbDup2 = ascombnbDup2.sort(['TestStartDate','TestStandardError','TestRITScore','TestDurationMinutes'], ascending=[1,0,1,1]) dups2use = ascombnbDup2.groupby(['TermName', 'SchoolName', 'StudentID', 'Discipline']).tail(1) </code></pre>  <p>Thanks!</p>