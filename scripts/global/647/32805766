<p>I use <code>bulk_create</code> to insert 1 mio records to a new table. It takes 80 seconds. Django only uses one CPU core (roughly 25% CPU, but no core is reaching 100%) I believe there is improvement potential. </p>  <p>Here is the code</p>  <pre><code>class Stock(models.Model):     code = models.CharField(max_length=6, unique=True)     name = models.CharField(max_length=8)  class Watchers(models.Model):     date = models.DateField(db_index=True)     stock = models.ForeignKey(Stock, unique_for_date="date")     num = models.PositiveIntegerField(default=0)  batch = [] for input in inputs:     watcher = Watcher(date=input['date'], stock=get_stock(), num=input['num'])     batch.append(watcher) Watcher.objects.bulk_create(batch) </code></pre>  <p>I've tried several things:</p>  <ol> <li>Use a proper <code>batch_size</code>. The best value for me is roughly 4000. It takes 80-90 seconds.</li> <li>Use a <code>ThreadPool()</code>. It is much slower, roughly 120-140 seconds</li> <li>Remove the index on <code>DateField</code>. A bit slower than 1. </li> </ol>  <p>I'm using MySQL 5.6 community edition. Storage engine is MyISAM. Here is the config.</p>  <pre><code>[mysqld] server-id   = 1 default-storage-engine = MyISAM port        = 3306 socket      = /tmp/mysql.sock datadir     = "{MYSQLDATAPATH}" skip-external-locking explicit_defaults_for_timestamp = TRUE  # MyISAM # key-buffer-size = 32M max_allowed_packet = 16M  # CACHES AND LIMITS # tmp-table-size                 = 32M max-heap-table-size            = 32M query-cache-type               = 0 query-cache-size               = 0 max-connections                = 500 thread-cache-size              = 50 open-files-limit               = 65535 table-definition-cache         = 1024 table-open-cache               = 2048  # LOGGING log-bin       = mysql-bin binlog_format = mixed </code></pre>  <p>When I import another table (similar structure, same indices, but has 9 columns), it takes 15 minutes. The time increase is not linear.</p>  <p>Anything wrong with bulk_create?</p>