<p>Recently, I've stumbled upon an interview question where you need to write a code that's optimized for ARM, especially for iphone:</p>  <blockquote>   <p>Write a function which takes an array of char (ASCII symbols) and find   the most frequent character.</p>      <p><code>char mostFrequentCharacter(char* str, int size)</code></p>      <p>The function should be optimized to run on dual-core ARM-based   processors, and an infinity amount of memory.</p> </blockquote>  <p>On the face of it, the problem itself looks pretty simple and here is the simple implementation of the function, that came out in my head:</p>  <pre><code>#define RESULT_SIZE 127  inline int set_char(char c, int result[]) {     int count = result[c];     result[c] = ++count;     return count; }  char mostFrequentChar(char str[], int size) {     int result[RESULT_SIZE] = {0};      char current_char;     char frequent_char = '\0';      int current_char_frequency = 0;     int char_frequency = 0;      for(size_t i = 0; i&lt;size; i++)     {         current_char = str[i];         current_char_frequency = set_char(current_char, result);          if(current_char_frequency &gt;= char_frequency)         {             char_frequency = current_char_frequency;             frequent_char = current_char;         }     }      return frequent_char; } </code></pre>  <p>Firstly, I did some basic code optimization; I moved the code, that calculates the most frequent char every iteration, to an additional <code>for</code> loop and got a significant increase in speed, instead of evaluating the following block of code <code>size</code> times</p>  <pre><code>if(current_char_frequency &gt;= char_frequency) {     char_frequency = current_char_frequency;     frequent_char = current_char; } </code></pre>  <p>we can find a most frequent char in <code>O(RESULT_SIZE)</code> where <code>RESULT_SIZE == 127</code>.</p>  <pre><code>char mostFrequentCharOpt1(char str[], int size) {     int result[RESULT_SIZE] = {0};      char frequent_char = '\0';      int current_char_frequency = 0;     int char_frequency = 0;      for(int i = 0; i&lt;size; i++)     {         set_char(str[i], result);     }      for(int i = 0; i&lt;RESULT_SIZE; i++)     {         current_char_frequency = result[i];          if(current_char_frequency &gt;= char_frequency)         {             char_frequency = current_char_frequency;             frequent_char = i;         }     }      return frequent_char; } </code></pre>  <p>Benchmarks: iPhone 5s</p>  <pre><code>size = 1000000 iterations = 500  // seconds = 7.842381 char mostFrequentChar(char str[], int size)  // seconds = 5.905090 char mostFrequentCharOpt1(char str[], int size) </code></pre>  <p>In average, the <code>mostFrequentCharOpt1</code> works in ~24% faster than basic implementation.</p>  <p><strong>Type optimization</strong></p>  <p>The ARM cores registers are 32-bits long. Therefore, changing all local variables that has a type char to type int prevents the processor from doing additional instructions to account for the size of the local variable after each assignment.</p>  <p><em>Note: The ARM64 provides 31 registers (x0-x30) where each register is 64 bits wide and also has a 32-bit form (w0-w30). Hence, there is no need to do something special to operate on <code>int</code> data type.</em> <a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/BABHDEEJ.html" rel="nofollow">infocenter.arm.com - ARMv8 Registers</a></p>  <p>While comparing functions in assembly language version, I've noticed a difference between how the ARM works with <code>int</code> type and <code>char</code> type. The ARM uses LDRB instruction to load byte and STRB instruction to store byte into individual bytes in memory. Thereby, from my point of view, LDRB is a bit slower than LDR, because LDRB do zero-extending every time when accessing a memory and load to register. In other words, we can't just load a byte into the 32-bit registers, we should cast byte to word.</p>  <p>Benchmarks: iPhone 5s</p>  <pre><code>size = 1000000 iterations = 500  // seconds = 5.905090 char mostFrequentCharOpt1(char str[], int size)  // seconds = 5.874684 int mostFrequentCharOpt2(char str[], int size) </code></pre>  <p>Changing <code>char</code> type to <code>int</code> didn't give me a significant increase of speed on iPhone 5s, by way of contrast, running the same code on iPhone 4 gave a different result:  </p>  <p>Benchmarks: iPhone 4</p>  <pre><code>size = 1000000 iterations = 500  // seconds = 28.853877 char mostFrequentCharOpt1(char str[], int size)  // seconds = 27.328955 int mostFrequentCharOpt2(char str[], int size) </code></pre>  <p><strong>Loop optimization</strong></p>  <p>Next, I did a loop optimization, where, instead of incrementing <code>i</code> value, I decremented it. </p>  <pre><code>before     for(int i = 0; i&lt;size; i++) { ... }  after for(int i = size; i--) { ... } </code></pre>  <p>Again, comparing assembly code, gave me a clear distinction between the two approaches.</p>  <pre><code>mostFrequentCharOpt2                                              |      mostFrequentCharOpt3 0x10001250c &lt;+88&gt;:  ldr    w8, [sp, #28] ; w8 = i                 |      0x100012694 &lt;+92&gt;:  ldr    w8, [sp, #28]                                             ; w8 = i 0x100012510 &lt;+92&gt;:  ldr    w9, [sp, #44] ; w9 = size              |      0x100012698 &lt;+96&gt;:  sub    w9, w8, #1 ; w9 = i - 1                                            0x100012514 &lt;+96&gt;:  cmp    w8, w9 ; if i&lt;size                     |      0x10001269c &lt;+100&gt;: str    w9, [sp, #28] ; save w9 to memmory 0x100012518 &lt;+100&gt;: b.ge   0x100012548 ; if true =&gt; end loop      |      0x1000126a0 &lt;+104&gt;: cbz    w8, 0x1000126c4 ; compare w8 with 0 and if w8 == 0 =&gt; go to 0x1000126c4 0x10001251c &lt;+104&gt;: ... set_char start routine                    |      0x1000126a4 &lt;+108&gt;: ... set_char start routine ...                                                               |      ... 0x100012534 &lt;+128&gt;: ... set_char end routine                      |      0x1000126bc &lt;+132&gt;: ... set_char end routine 0x100012538 &lt;+132&gt;: ldr    w8, [sp, #28] ; w8 = i                 |      0x1000126c0 &lt;+136&gt;: b      0x100012694 ; back to the first line 0x10001253c &lt;+136&gt;: add    w8, w8, #1 ; i++                       |      0x1000126c4 &lt;+140&gt;: ... 0x100012540 &lt;+140&gt;: str    w8, [sp, #28] ; save i to $sp+28       |       0x100012544 &lt;+144&gt;: b      0x10001250c ; back to the first line   |       0x100012548 &lt;+148&gt;: str    ...                                    |       </code></pre>  <p>Here, in place of accessing <code>size</code> from the memory and comparing it with the <code>i</code> variable, where the <code>i</code> variable, was incrementing, we just decremented <code>i</code> by 0x1 and compared the register, where the <code>i</code> is  stored, with 0.</p>  <p>Benchmarks: iPhone 5s</p>  <pre><code>size = 1000000 iterations = 500  // seconds = 5.874684 char mostFrequentCharOpt2(char str[], int size) //Type optimization  // seconds = 5.577797 char mostFrequentCharOpt3(char str[], int size) //Loop otimization </code></pre>  <p><strong>Threading optimization</strong></p>  <p>Reading the question accurately gives us at least one more optimization. This line <code>..optimized to run on dual-core ARM-based processors ...</code> especially, dropped a hint to optimize the code using pthread or gcd. </p>  <pre><code>int mostFrequentCharThreadOpt(char str[], int size) {     int s;     int tnum;     int num_threads = THREAD_COUNT; //by default 2     struct thread_info *tinfo;      tinfo = calloc(num_threads, sizeof(struct thread_info));      if (tinfo == NULL)         exit(EXIT_FAILURE);      int minCharCountPerThread = size/num_threads;     int startIndex = 0;      for (tnum = num_threads; tnum--;)     {         startIndex = minCharCountPerThread*tnum;          tinfo[tnum].thread_num = tnum + 1;         tinfo[tnum].startIndex = minCharCountPerThread*tnum;         tinfo[tnum].str_size = (size - minCharCountPerThread*tnum) &gt;= minCharCountPerThread ? minCharCountPerThread : (size - minCharCountPerThread*(tnum-1));         tinfo[tnum].str = str;          s = pthread_create(&amp;tinfo[tnum].thread_id, NULL,                            (void *(*)(void *))_mostFrequentChar, &amp;tinfo[tnum]);         if (s != 0)             exit(EXIT_FAILURE);     }      int frequent_char = 0;     int char_frequency = 0;     int current_char_frequency = 0;      for (tnum = num_threads; tnum--; )     {         s = pthread_join(tinfo[tnum].thread_id, NULL);     }      for(int i = RESULT_SIZE; i--; )     {         current_char_frequency = 0;          for (int z = num_threads; z--;)         {             current_char_frequency += tinfo[z].resultArray[i];         }          if(current_char_frequency &gt;= char_frequency)         {             char_frequency = current_char_frequency;             frequent_char = i;         }     }      free(tinfo);      return frequent_char; } </code></pre>  <p>Benchmarks: iPhone 5s</p>  <pre><code>size = 1000000 iterations = 500  // seconds = 5.874684 char mostFrequentCharOpt3(char str[], int size) //Loop optimization  // seconds = 3.758042 // THREAD_COUNT = 2 char mostFrequentCharThreadOpt(char str[], int size) //Thread otimization </code></pre>  <p>Note: mostFrequentCharThreadOpt works slower than mostFrequentCharOpt2 on iPhone 4.</p>  <p>Benchmarks: iPhone 4</p>  <pre><code>size = 1000000 iterations = 500  // seconds = 25.819347 char mostFrequentCharOpt3(char str[], int size) //Loop optimization  // seconds = 31.541066 char mostFrequentCharThreadOpt(char str[], int size) //Thread otimization </code></pre>  <p><strong>Question</strong></p>  <p>How well optimized is the <code>mostFrequentCharOpt3 and mostFrequentCharThreadOpt</code>, in other words: are there any other methods to optimize both methods?</p>  <p><a href="https://github.com/tikhop/MostFrequentChar" rel="nofollow"><strong>Source code</strong></a></p>