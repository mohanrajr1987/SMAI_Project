<p>So, I'm looping through a bunch of docs creating a list of all unique words and sequential groups of words in the documents (obviously, the strings I'm looking at are pretty short).</p>  <pre><code>globallist=[] for filename in glob.glob(os.path.join(path, '*.html')):      mystr = "some text I want"      stuff = re.sub("[^\w]", " ",  mystr).split()      wordlist = [''.join(stuff[i:j]) for i in range(len(stuff)) for j in range(i+1, len(stuff)+1)]      globallist = set.union(set(globallist), set(wordlist)) </code></pre>  <p>I want to track occurrences with globallist as I go so that at the end I'll already have a count of <strong><em>how many documents</em></strong> contain each string in the list. I plan to delete any element that only occurs in one document. What's the best way to do this?</p>